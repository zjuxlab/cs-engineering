---
title: 集群
slug: 集群
sidebar_position: 4
---


# 集群

> A cluster of mongos
> 好多芒果😯

# 概述

MongoDB共有两种集群方案

- ReplicaSet 副本集
    - 主RW，从RO

- Sharding 分片
    - 同一个集合分散存储

# ReplicaSet

@see  https://www.mongodb.com/docs/manual/replication/

## 运行流程

- 查询时，主机向从机分发查询（或client直接访问从机），从而达到读取的负载均衡
- 写入时，更新主机，然后主机向从机进行同步 (oplog)

![](/assets/O4MWbV7qgoZWllxugp0cMH1EnrU.png)

## 节点类型

![](/assets/UgYKbkpk5oCBb4xXwwpcn5dfnCe.png)

- 主节点：提供读取和写入
- 从节点：接受主节点的写入同步；如果开启`rs.slaveOk()`则同时允许client直接读取
- 仲裁节点：主节点挂了之后辅助选举新的主节点；不存储数据
    - 使投票节点数量始终保持奇数

<div class="callout callout-bg-2 callout-border-2">
<div class='callout-emoji'>❓</div>
<p>好像是1主1从下才必须加一个仲裁？？</p>
<p><em>好像也支持没有仲裁节点？有没有都可以的话，这玩意到底用处是啥？</em></p>
</div>

## 容灾模式

![](/assets/L3blbYzjkoX6dTxxxwycE3lPnke.png)

正常情况下，数据节点会按照`2s`的时间间隔互相发送心跳包；当

当主节点超过`electionTimeoutMillis`时长没有心跳，则启动容灾程序(Automatic Failover)，在存活的从节点中选举出一个升级为主节点。

> 如果主节点挂的时候，数据同步没有完成；当挂的主节点重新加入集群，会触发[Rollbacks During Replica Set Failover](https://www.mongodb.com/docs/manual/core/replica-set-rollbacks/#std-label-replica-set-rollback)

> Client Driver也需要配合检测异常并更换主节点（通常是自动的）

## 从机设置

https://www.mongodb.com/docs/manual/core/replica-set-secondary/

- Priority 竞选主机的优先级；越低越不愿意成为主机（例如由于延迟或性能）
- Hidden 仅同步数据；不处理查询请求
- <u>Delayed 延迟写入同步数据；可以作为删库的恢复手段</u>

## 副本集设置

【缓存预热】

https://www.mongodb.com/docs/manual/replication/#std-label-mirrored-reads

从机为了应对可能突发升级为主机，会采样部分主机进行的查询，在本地进行查询来保持cache的内容和主机相似，从而提升Failover后的查询效率

【流量控制】

https://www.mongodb.com/docs/manual/tutorial/troubleshoot-replica-sets/#std-label-flow-control

为了降低主从之间的同步延迟，可以启动流量控制；当主机检测到同步时间超过 `flowControlTargetLagSeconds` 就会降低写入并发量

【数据一致性】

当主从同步正在进行，而client又发生了查询请求，则需要控制是否等待同步接收

https://www.mongodb.com/docs/manual/core/read-isolation-consistency-recency/

## 副本集部署

首先启动mongo实例（典型情况是1主2从）

然后在其中一个实例上运行：

```js
rs.initiate( {
   _id : "replica set's name",
   members: [
      { _id: 0, host: "host1" },
      { _id: 1, host: "host2" },
      { _id: 2, host: "host3" }
   ]
})
```

<div class="callout callout-bg-2 callout-border-2">
<div class='callout-emoji'>❓</div>
<p>官网上没有说清楚从非空数据库构建ReplicaSet的特殊情况处理</p>
<p>比如，不同实例的数据不一致；密码不一致等</p>
<p>这个需要实践出真知，有待补充</p>
</div>

# Sharding

@see https://www.mongodb.com/docs/manual/sharding/

## 架构

- Router 负责接受用户请求，分发给对应的shard
- Shard  储存部分数据的分片
- Config Server 储存metadata的db

![](/assets/EabfbacBdoqCbCx48vnc9CMynzf.png)

NODE：Mongo Sharding Cluster的每个Shard都维护所有Collection；

分片是对同一Collection中的document进行分散

## 节点类型

<div class="callout callout-bg-7">
<div class='callout-emoji'>💬</div>
<p>3.6版本中，除去mongos，所有节点必须本身是一个Replica Set集群（套娃）</p>
<p>TODO 之后的新版本好像是可以单mongod进程（？）</p>
</div>

### Shard

根据Shard Key的分片策略，存储特定部分的数据。

没啥可说的，本质就是正常的DB

<div class="callout callout-bg-2">
<div class='callout-emoji'>❗</div>
<p> 开启分片之后，不应该由Client直接访问Shard节点；因为只存储了部分数据</p>
</div>

### Router

只进行分发，不怎么占用资源；是单独的服务，没有MongoDB存储实例

<div class="callout callout-bg-7">
<div class='callout-emoji'>💬</div>
<p>特定的aggregate操作需要在mongos上处理</p>
<p><a href="https://www.mongodb.com/docs/manual/core/sharded-cluster-query-router/#routing-and-results-process">https://www.mongodb.com/docs/manual/core/sharded-cluster-query-router/#routing-and-results-process</a></p>
</div>

### Config Server

存储各种非常非常重要的东西，简单来说，就是没事别动他。

使用mongosh的管理指令修改Sharding配置。

![](/assets/CXMcbaMQkoGeeNxNuQWcTnFgnbc.png)

## Shard Key

ShardKey是特殊的单键或复合索引；

通过这个Index，mongos可以判断哪些数据该存储在那个Shard中

如何选用Shard Key：

https://www.mongodb.com/docs/manual/core/sharding-choose-a-shard-key/

和SQL一样，这个索引也支持Range和Hash两种方式。

## 查询策略

主要分为两种：

- Targeted 指向性查询：通过Shard Key 将数据导向特定Shard进行查询
- Broadcast 广播查询：给每一个Shard发送查询请求，最后手动合并

## 数据层级结构

> to be continued...

- Shard
- Chunk
- Zone
- Cluster

