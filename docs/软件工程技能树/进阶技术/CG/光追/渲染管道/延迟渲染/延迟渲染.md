---
title: 延迟渲染
slug: 延迟渲染
sidebar_position: 0
---


# 延迟渲染

Author: 周楷程

# 前向渲染

在学习渲染管线时，最先学到的应该就是前向渲染。

简单来说，前向渲染首先对所有顶点跑了一遍顶点着色器，再对所有片元跑了一遍片元着色器。关键在于片元着色器的计算部分。在计算光照影响时，对于每一个片元，我们都要把它和所有可能有关的光源之间做计算。假设我们有 N 个片元，M 个光照，那么计算的复杂度就和 N*M 有关。

但事实上，有很多片元是被遮挡的，这就导致了很多光照计算是无用的，而光照计算本身就是一个计算量很大的环节。

有一个改进的思路，就是在片元着色器内先进行深度测试，丢弃被遮挡的片元。在做之前还可以对物体进行前后排序以达到更好的效果。这确实可以减小一些成本，但是在一些复杂的场景下依然不够理想。

为了进一步节省计算成本，前辈们提出了延迟渲染（Deferred Rendering）。

# 延迟渲染

延迟渲染的思路就是在于把计算光照的部分分成两个 Pass，从而把光照计算完全放到深度测试之后。

1. 几何处理：首先对于所有片元，将所有计算光照需要用到的属性存储进帧缓冲 G-Buffer。一般包含法线、漫反射颜色、镜面幂、反射率等等。这里会用到一个 MRT 技术（Multiple Render Targets，可以支持同时输出到多个目标纹理）。对于深度测试失败的片元就直接丢弃。所以在这一个 Pass 结束之后，G-Buffer 内就存储下了屏幕上每个像素对应的片元的属性。
2. 光照处理：这一个 Pass 我们只需要渲染出屏幕大小的一个矩形。对于每一个像素，利用在前一个 Pass 中输出的属性信息来计算光照。在这一步，所有被遮挡的片元都已被丢弃，只剩下了离相机最近的片元。

如此一来，计算的复杂度就和 N*M 无关了。

## G-Buffer

G-Buffer（几何缓冲）是一个逻辑上的集合，它包含了很多 2D 纹理。在几何处理阶段，着色器会将多个属性输出到这些纹理当中，以供光照处理阶段使用。

也正因如此，几何缓冲占用的显存带宽会很大，因为对于一个渲染窗口会存很多张纹理。

## 光照处理阶段的优化

实际上，有些光源可能比较弱，对于离它较远的物体可能不会产生任何显著影响。我们尝试把这些无用的计算也除去。

对于每个光源，构建一个大于其衰减范围的顶点数较少的粗糙几何体（对于点光源是球体，对于聚光灯是圆锥体）。利用顶点着色器把这些几何体变换到裁剪空间，每一个光源就可以只对它可能影响到的片元进行计算。

# 延迟渲染的优缺点

优点：

1. 在计算复杂度上将场景中的物体数量（片元数量）与光源数量分开，不再是相乘的关系；
2. 可以更好地支持大量光源的场景。

缺点：

1. 直接这样做不能支持透明物体的渲染。需要和前向渲染结合（如先渲染所有透明物体）；
2. 内存开销大，占用带宽高；
3. 不能很好的支持 MSAA。

# 延迟渲染与 MSAA

由于延迟渲染的过程丢失了原有的几何位置信息，所以在光照计算阶段无法进行 MSAA 过程。

但是，你可能会有一些疑问。

1. 为什么不能在 G-Buffer 里存入更多信息？直接存入 4 倍的属性信息！
这样确实可以做到 AA，但是采样 4 倍的话最后也就要做 4 次光照计算，这就不是 MSAA 了，而是 SSAA，这样开销太大。
2. 那为什么不能在几何处理阶段就进行多采样，保留平均后的颜色？
因为 MSAA 是对光照计算完后的颜色值进行采样平均，而不是对 base color。只对 base color 采样平均再计算光照得出的结果可能不正确。
3. 那延迟渲染真的完全不能支持 MSAA 吗？
其实可以通过设计 G-Buffer 内容、修改光照计算算法等方法在可接受的成本内实现延迟渲染的 MSAA。但可能并不能达到 MSAA 在前向渲染下的优秀表现。

