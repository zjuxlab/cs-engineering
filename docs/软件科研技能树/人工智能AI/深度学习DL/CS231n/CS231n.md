---
title: CS231n
slug: CS231n
sidebar_position: 0
---


# CS231n

Author：欧阳创宇

负责人：

# 线性回归

<em>回归</em>是能为一个或多个自变量与因变量之间关系建模的一类方法。<em>线性回归</em>可以追溯到19世纪初， 它在回归的各种标准工具中最简单而且最流行。 线性回归基于几个简单的假设： 首先，假设自变量 $\textbf{x}$ 和因变量 $y$ 之间的关系是线性的， 即 $y$ 可以表示为 $\textbf{x}$ 中元素的加权和，这里通常允许包含观测值的一些噪声； 其次，我们假设任何噪声都比较正常，如噪声遵循正态分布。

## 线性模型

线性回归的一个例子是对房价的预测。 我们希望根据房屋的面积（平方英尺）和房龄（年）来估算房屋价格（美元）。 为了开发一个能预测房价的模型，我们需要收集一个真实的数据集。 这个数据集包括了房屋的销售价格、面积和房龄。 在机器学习的术语中，该数据集称为<em>训练数据集</em> 或<em>训练集</em>。 每行数据（比如一次房屋交易相对应的数据）称为<em>样本</em>， 也可以称为<em>数据点</em>或<em>数据样本</em>。 我们把试图预测的目标（比如预测房屋价格）称为<em>标签</em>或<em>目标</em>。 预测所依据的自变量（面积和房龄）称为<em>特征</em>或<em>协变量</em>。

对于这个例子，我们可以假设如下的线性模型：

$$
price = \omega_{area} \cdot area + \omega_{age} \cdot age + b$$

其中 $\omega_{area}$ , $\omega_{age}$ 称为权重，$b$ 称为偏置。线性回归所做的，就是通过给定的数据集寻找合适的模型权重 $\omega$ 和 偏置 $b$ ，使得根据模型做出的预测大体符合数据里的真实价格。这样的模型是对输入特征的仿射变换，通过加权和来对特征进行线性变换，通过偏置来进行平移。

由于机器学习领域中通常使用的是高维的数据集，因此在模型的表示上用线性代数表示会比较方便。假设输入包含 $d$ 个特征，则预测结果 $\hat{y}$ 可表示为：

$$
\hat{y} = \textbf{w}^T\textbf{x} + b$$

其中 $\textbf{x} \in \mathbb{R}^d$ 为特征向量， $\textbf{w} \in \mathbb{R}^d$ 为权重向量。这个式子是对单个数据样本的模型，对于整个数据集，可以用矩阵 $\textbf{X} \in \mathbb{R}^{n \times d}$ 表示，其中 $\textbf{X}$ 的行数表示样本数量，列数表示特征维数。对于这样的样本矩阵 $\textbf{X}$ ，预测值 $\hat{\textbf{y}} \in \mathbb{R}^n$ 可以用如下式子表示：

$$
\hat{\textbf{y}} = \textbf{Xw} + b$$

## 损失函数

在寻找合适的模型参数 $\textbf{w}$ 和 $b$ 之前，我们需要先定义如何来衡量一组参数的优劣。<em>损失函数</em>（loss function）能够量化目标的实际值与预测值之间的差距。 通常我们会选择非负数作为损失，且数值越小表示损失越小，完美预测时的损失为 0 。

在回归问题中很常用的一种损失函数是平方误差函数。当样本 $i$ 的预测值为 $\hat{y}^{(i)}$ ，其对应的真实值为 $y^{(i)}$ 时，平方误差可以定义为如下公示：

$$
l^{(i)}(\textbf{w}, b) = \frac12(\hat{y}^{(i)}-y^{(i)})^2$$

这里常数 $\frac12$ 主要是使得损失函数在求导后常数系数为 $1$ ，形式更美观。对于度量模型在整个数据集上的表现，还需要对每一个数据样本的损失值求和，即

$$
L(\textbf{w}, b) = \frac1n \sum_{i=1}^n l^{(i)}(\textbf{w}, b) = \frac1n \sum_{i=1}^n \frac12 (\textbf{w}^T\textbf{x}^{(i)} + b - y^{(i)}) ^2$$

有了参数质量的衡量方法，我们便可以明确模型训练的目标，即寻找一组参数 $(\textbf{w}^*, b^*)$ ，使得线性回归模型在所有训练样本上的总损失最小，也即下式：

$
\textbf{w}^*, b^* = \mathop{\text{argmin}} \limits_{\textbf{w}, b} \ L(\textbf{w}, b)$$
\textbf{w}^*, b^* = \mathop{\text{argmin}} \limits_{\textbf{w}, b} \ L(\textbf{w}, b)$$
\textbf{w}^*, b^* = \mathop{\text{argmin}} \limits_{\textbf{w}, b} \ L(\textbf{w}, b)$

## 解析解

线性回归模型的优化是一个很简单的优化模型，可以通过数学计算得到一个简洁的解析解。在矩阵 $\textbf{X}$ 中添加一列 $1$ ，将参数 $b$ 加到 $\textbf{w}$ 中，可以将模型目标转化为最小化 $||\textbf{y} - \textbf{Xw}||^2$ ，由此可得到解析解

$$
\textbf{w}^* = (\textbf{X}^T \textbf{X})^{-1} \textbf{X}^T \textbf{y}$$

当然，解析解只有对这样简单的模型有效，并不是所有的问题都存在解析解。

## 随机梯度下降

在无法得到模型解析解的情况下，通过<em>梯度下降</em>的方式也可以有效地训练模型。这种方法的实现方式是不断地在损失函数递减的方向上更新参数来降低误差。为了降低计算的复杂度，在每次更新时往往会随即抽取一小批样本来代替整个数据集，这种变体叫做<em>小批量随机梯度下降</em> ，其具体执行步骤如下：

1. 初始化模型参数
2. 随机抽取一个小批量样本 $\mathcal{B}$
3. 计算该样本的平均损失关于模型参数的导数（称为梯度）
4. 将梯度乘以一个正数超参数 $\eta$ ，并从当前参数的值中减掉
5. 重复步骤 2 ~ 4 ，直到达到预先确定的迭代次数或满足某些停止条件

用数学公示来表示这一更新过程为：

$$
(\textbf{w}', b') = (\textbf{w}, b) - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_{(\textbf{w}, b)}l^{(i)}(\textbf{w}, b)$$

对于仿射变换和平方损失，这一更新式可以明确写为如下形式：

$$
\begin{align} \textbf{w}' &= \textbf{w} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_{\textbf{w}} l^{(i)}(\textbf{w}, b) =  \textbf{w} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \textbf{x}^{(i)} (\textbf{w}^T\textbf{x}^{(i)} + b - y^{(i)}) \\ b' &= b - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_{b} l^{(i)}(\textbf{w}, b) =  b - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}(\textbf{w}^T\textbf{x}^{(i)} + b - y^{(i)}) \end{align}$$

式中的 $|\mathcal{B}|$ 和 $\eta$ 分别表示随机抽取小批量样本 $\mathcal{B}$ 的样本数和学习率 $\eta$ ，它们不是通过训练得到的，而是在训练之前手动指定的，称为超参数。通常我们需要根据训练迭代的结果来调整超参数的选择。

## 正态分布与平方损失

如果考虑数据中存在噪声，且噪声服从正态分布，则模型可以做如下修改：

$$
y = \textbf{w}^T \textbf{x} + b + \epsilon$$

其中 $\epsilon \sim \mathcal{N}(0, \sigma^2)$ 。

由此可得由给定的 $\textbf{x}$ 得到特定结果 $y$ 的似然：

$$
P(y \mid \textbf{x}) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp((-\frac{1}{2\sigma^2}(y-\textbf{w}^T \textbf{x} - b)^2)$$

此时可由极大似然估计法来确定使得整个数据集似然最大的参数 $\textbf{w}$ 和 $b$ 的值。对整个数据集，似然值为：

$$
P(\textbf{y} \mid \textbf{X}) = \prod_{i=1}^n p(y^{(i)} \mid \textbf{x}^{(i)})$$

对此函数求负对数（由于历史原因，优化通常是说最小化而不是最大化，所以取负），可得：

$$
-\ln P(\textbf{y} \mid \textbf{X}) = \sum_{i=1}^n \frac12 \ln(2 \pi \sigma^2) + \frac{1}{2 \sigma^2}(y^{(i)} - \textbf{w}^T \textbf{x}^{(i)} + b)^2$$

可见如果我们假设噪声方差 $\sigma^2$ 是固定常数，那么对含噪声模型的极大似然估计与之前分析的最小化均方误差是等价的。

## 神经网络图

线性回归模型实际上可以看作是单个的计算神经元，如下图。在这种表示中，图上只显示了连接方式，而隐去了权重和偏置的值。

![](/assets/UplRbgivMotFA0xQ47Ncm9t0nKe.png)

对于线性回归，每个输入都与每个输出相连，我们称这种变换为<em>全连接层</em>或<em>稠密层</em>。

# 线性回归的从零开始实现

## 导入相关库

```py
import random
import torch
from d2l import torch as d2l
```

## 生成数据集

在本次实践中，我们将根据带有噪声的线性模型来构造一个人造数据集，然后试图利用线性回归的方法通过这个数据集来恢复模型的参数。在下面的代码中，我们生成一个包含 1000 个样本的数据集， 每个样本包含从标准正态分布中采样的2个特征。

我们使用的线性模型参数为 $\textbf{w} = [2, -3.4]^T$ 、$b = 4.2$ 和噪声项 $\epsilon \sim \mathcal{N}(0, 0.01)$ 生成数据集及其标签：

$$
y = \textbf{Xw} + b + \epsilon$$

我们用如下代码进行数据集的生成：

```py
def synthetic_data(w, b, num_examples):
    X = torch.normal(0, 1, (num_examples, len(w)))
    y = torch.matmul(X, w) + b
    y += torch.normal(0, 0.01, y.shape)
    return X, y.reshape((-1, 1))

true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = synthetic_data(true_w, true_b, 1000)
```

得到的 `features` 的每一行为一个二维的数据样本，`labels` 每一行为对应的标签值。

```py
print('features:', features[0],'\nlabel:', labels[0])
```

```text
features: tensor([ 0.7579, -0.4018]) 
label: tensor([7.0914])
```

通过生成第二个特征 `features[:, 1]` 和 `labels` 的散点图， 可以直观观察到两者之间的线性关系。

```py
d2l.set_figsize()
d2l.plt.scatter(features[:, 1].detach().numpy(), labels.detach().numpy(), 1);
d2l.plt.show()
```

![](/assets/Uz5ybmAPdo0QZUxnFBLcWWVOnqb.png)

## 读取数据集

在线性回归模型训练的过程中，每次取出的是其中的一份小批量数据集用于更新参数。为了方便地取出小批量随即数据集，我们定义一个函数来做这件事。

```py
def data_iter(batch_size, features, labels):
    num_examples = len(features)
    indices = list(range(num_examples))
    random.shuffle(indices)
    for i in range(0, num_examples, batch_size):
        batch_indices = torch.tensor(
            indices[i: min(i + batch_size, num_examples)])
        yield features[batch_indices], labels[batch_indices]
```

这个函数通过 `yield` 关键字成为了一个生成器，可以很方便地用在迭代中，如下：

```py
batch_size = 10

for X, y in data_iter(batch_size, features, labels):
    # do something...
```

## 初始化模型参数

根据模型训练的流程，首先需要给一个初始的参数。这里我们通过正态分布得到一个随机的初始权重，并把初始偏置设为 0 。由于需要计算损失函数对参数的导数，故设 `requires_grad` 为 `True` 。

```py
w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)
b = torch.zeros(1, requires_grad=True)
```

## 定义模型

模型的定义也就是把模型的输入（数据集）和参数与输出关联起来，于是可以得到如下函数：

```py
def linreg(X, w, b):
    return torch.matmul(X, w) + b
```

## 定义损失函数

模型优化的一大核心便是损失函数对各参数的导，所以损失函数的定义也是必要的一步。在这里我们使用前文提到的平方损失函数。

```py
def squared_loss(y_hat, y):
    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2
```

## 定义优化算法

接下来就可以定义迭代过程中参数优化的算法了。这里采用的是前文讲述的小批量随机梯度下降更新。

```py
def sgd(params, lr, batch_size):
    with torch.no_grad():
        for param in params:
            param -= lr * param.grad / batch_size
            param.grad.zero_()
```

这里通过 `with torch.no_grad()` 将更新过程包裹起来，其目的是防止将更新参数的计算步骤也纳入计算图中影响反向传播。

## 训练

上述内容都定义好了之后，就可以正式把它们搭起来，实现主要的训练部分了。这里再把训练过程简要概括一下：

1. 初始化参数
2. 抽取样本
3. 计算梯度
4. 更新参数

在每个迭代周期中，我们通过 `data_iter` 函数来遍历整个数据集，对参数进行更新。这里的迭代次数 `num_epochs` 、小批量训练集大小 `batch_size` 和学习率 `lr` 都是超参数。

```py
lr = 0.03
num_epochs = 3
batch_size = 10
net = linreg
loss = squared_loss

for epoch in range(num_epochs):
    for X, y in data_iter(batch_size, features, labels):
        l = loss(net(X, w, b), y)
        l.sum().backward()
        sgd([w, b], lr, batch_size)
    with torch.no_grad():
        train_l = loss(net(features, w, b), labels)
        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')
```

在上述超参数的设置下，模型训练得到的结果是：

```text
epoch 1, loss 0.037547
epoch 2, loss 0.000137
epoch 3, loss 0.000047
```

事实上由于真正的参数是已知的，所以我们可以直接对真实的参数和训练得到的参数进行比较。

```py
print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')
print(f'b的估计误差: {true_b - b}')
```

结果如下：

```text
w的估计误差: tensor([-1.9073e-05, -5.3620e-04], grad_fn=<SubBackward0>)
b的估计误差: tensor([0.0003], grad_fn=<RsubBackward1>)
```

可以看到两者误差非常小。

## 完整代码

```py
import random
import torch
from d2l import torch as d2l

def synthetic_data(w, b, num_examples):
    X = torch.normal(0, 1, (num_examples, len(w)))
    y = torch.matmul(X, w) + b
    y += torch.normal(0, 0.01, y.shape)
    return X, y.reshape((-1, 1))

def data_iter(batch_size, features, labels):
    num_examples = len(features)
    indices = list(range(num_examples))
    random.shuffle(indices)
    for i in range(0, num_examples, batch_size):
        batch_indices = torch.tensor(
            indices[i: min(i + batch_size, num_examples)])
        yield features[batch_indices], labels[batch_indices]

def linreg(X, w, b):
    return torch.matmul(X, w) + b

def squared_loss(y_hat, y):
    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2

def sgd(params, lr, batch_size):
    with torch.no_grad():
        for param in params:
            param -= lr * param.grad / batch_size
            param.grad.zero_()

true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = synthetic_data(true_w, true_b, 1000)

w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)
b = torch.zeros(1, requires_grad=True)

lr = 0.03
num_epochs = 3
batch_size = 10
net = linreg
loss = squared_loss

for epoch in range(num_epochs):
    for X, y in data_iter(batch_size, features, labels):
        l = loss(net(X, w, b), y)
        l.sum().backward()
        sgd([w, b], lr, batch_size)
    with torch.no_grad():
        train_l = loss(net(features, w, b), labels)
        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')

print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')
print(f'b的估计误差: {true_b - b}')
```

# 线性回归的简洁实现

简洁实现指利用深度学习框架封装好的 api 进行训练代码的编写。一个简单的例子如下，实现的仍然是第 2 部分的内容。

```py
import numpy as np
import torch
from torch import nn
from torch.utils import data
from d2l import torch as d2l

def load_array(data_arrays, batch_size, is_train=True):
    dataset = data.TensorDataset(*data_arrays)
    return data.DataLoader(dataset, batch_size, shuffle=is_train)
    # 将数据按照 batch_size 封装，便于后续迭代使用

true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = d2l.synthetic_data(true_w, true_b, 1000)

batch_size = 10
data_iter = load_array((features, labels), batch_size)

net = nn.Sequential(nn.Linear(2, 1))
"""
Sequential类将多个层串联在一起。 当给定输入数据时，Sequential实例将数据传入到第一层，
然后将第一层的输出作为第二层的输入，以此类推。
在本例中用到的层被称为全连接层（fully-connected layer）， 因为它的每一个输入都通过
矩阵-向量乘法得到它的每个输出。在PyTorch中，全连接层在Linear类中定义。 值得注意的是，
我们将两个参数传递到nn.Linear中。第一个指定输入特征形状，即2，第二个指定输出特征形状，
输出特征形状为单个标量，因此为1。
"""
net[0].weight.data.normal_(0, 0.01)
net[0].bias.data.fill_(0)

loss = nn.MSELoss()
# 计算均方误差使用的是MSELoss类，也称为平方范数。 默认情况下，它返回所有样本损失的平均值。
trainer = torch.optim.SGD(net.parameters(), lr=0.03)

num_epochs = 3
for epoch in range(num_epochs):
    for X, y in data_iter:
        l = loss(net(X) ,y)
        trainer.zero_grad()
        # 清除上一次的梯度
        l.backward()
        trainer.step()
    l = loss(net(features), labels)
    print(f'epoch {epoch + 1}, loss {l:f}')

w = net[0].weight.data
print('w的估计误差：', true_w - w.reshape(true_w.shape))
b = net[0].bias.data
print('b的估计误差：', true_b - b)
运行结果：
epoch 1, loss 0.000341
epoch 2, loss 0.000094
epoch 3, loss 0.000095
w的估计误差： tensor([0.0010, 0.0005])
b的估计误差： tensor([0.0004])
```

# softmax 回归

分类问题可以分为两类：1. 只关心样本属于哪一类别；2. 希望得到样本属于每一类别的概率。前者称为硬类别，后者称为软类别。通常情况下，即使我们只关心硬类别，在模型的构建中仍然会使用软类别。

## 分类问题

我们以图像分类问题为例来构建软分类问题的输入输出要素。假设每次输入的是一张 $2 \times 2$ 的灰度图像，则我们可以用一个标量来表示每一个像素值，那么每张图像对应四个特征值 $x_1, x_2, x_3, x_4$ 。于是输入转化成了和线性回归模型一样的形式。

对于输出，假设每张图像属于类别“猫”“鸡”和“狗”中的一个，那么一个很明显的想法是选择 $y \in \{1, 2, 3\}$ ，每个整数分别代表一个动物。这种标签对于有自然顺序关系的分类比较有意义，例如年龄段的分类 $\{\text{婴儿}, \text{儿童}, \text{青少年}, \text{青年人}, \text{中年人}, \text{老年人}\}$ 。但是对于我们这个例子，当最后得到的结果落在某两个标签之间时，它的意义并不明确。于是我们考虑另外一种标签：<em>独热编码</em>（one-hot encoding）。这种编码方式的输出结果是一个向量，它的维度和类别一样多，类别对应的分量是 $1$ ，其余分量是 $0$ 。在此例中，标签 $y$ 是一个三维向量，其中 $(1, 0, 0)$ 对应“猫”，$(0, 1, 0)$ 对应“鸡”，$(0, 0, 1)$ 对应狗，即：

$$
y \in \{(1, 0, 0), (0, 1, 0), (0, 0, 1)\}$$

联系我们之前提到的软类别，这种编码方式实际也可以看作样本属于每一类的概率，于是模型计算得到的样本标签应该是一个各分量为非负数且和为 $1$ 的向量。         

至此，输入输出要素已经构建完毕。

## 网络架构

由 4.1 得到的输入输出可知，软分类问题实际需求就是根据输入的特征值来计算输出向量的值。这就回到了前文所述的回归问题，只不过这次的模型不再是一个输出，而是有多个输出。因此，我们需要构建和输出维度数量一致的仿射变换式，每一个式子对应一个类别的输出。在本例中，由于我们有 4 个特征和 3 个可能的输出类别， 我们将需要 12 个标量来表示权重（带下标的 $w$ ）， 3个标量来表示偏置（带下标的 $b$ ）。 下面我们为每个输入计算三个<em>未规范化的预测</em>（logit）：$o_1$、$o_2$ 和 $o_3$ 。

$$
\begin{align} o_1 &= x_1 w_{11} + x_2 w _{12} + x_3 w_{13} + x_4 w_{14} + b_1 \\ o_2 &= x_1 w_{21} + x_2 w _{22} + x_3 w_{23} + x_4 w_{24} + b_2 \\ o_3 &= x_1 w_{31} + x_2 w _{32} + x_3 w_{33} + x_4 w_{34} + b_3 \end{align}$$

我们可以和之前的线性回归一样用神经网络图来描述这个过程。这里的输出层也是全连接层。

![](/assets/UmHZbzv0QoNOqPx9Sy9cWEXinXg.png)

同样我们也可以用线性代数的表示方式来简化上述仿射变换式，即

$$
\textbf{o} = \textbf{Wx} + \textbf{b}$$

## softmax 运算

对于一个样本，我们希望模型的输出 $\hat{y_j}$ 可以视为此模型属于类 $j$ 的概率，然后选择具有最大输出值的类别 $\text{argmax}_j y_j$ 作为预测类别。现在模型优化的目标就是寻找合适的参数来最大化目标数据的概率值。然而仅由 4.2 中得到的模型输出 $o$ 并不能直接作为我们想得到的概率输出值，因为我们并没有对仿射变换式加以限制，导致输出向量各维度之和不一定是 $1$ ，同时各维度上的分量也可能出现负数。

为了解决这个问题我们可以对得到的 $\textbf{o}$ 应用 <em>softmax</em> 函数：

$$
\hat{\textbf{y}} = \text{softmax}(\textbf{o}) \quad \text{其中} \quad \hat{y_j} = \frac{\exp(o_j)}{\sum_k \exp(o_k)}$$

这个函数首先通过求幂将未规范化的预测限制在非负数集合内，然后再通过除以总和来使各维度分量之和为 $1$ ，因此，$\hat{\textbf{y}}$ 可以视为一个正确的概率分布。

尽管 softmax 是一个非线性函数，但是其输出仍然由输入特征的仿射变换决定，因此， softmax 回归是一个<em>线性模型</em>。

## 损失函数

### 对数似然

softmax 函数给出的向量 $\hat{\textbf{y}}$ 可以视为对给定输入 $\textbf{x}$ 的每个类的条件概率，例如还是对于上例，$\hat{y_1} = P(y = \text{猫} \mid \textbf{x})$ 。对于有 $n$ 个样本的数据集 $\{\textbf{X}, \textbf{Y}\}$ ，我们可以计算其似然值：

$$
P(\textbf{Y} \mid \textbf{X}) = \prod_{i=1}^n P(\textbf{y}^{(i)} \mid \textbf{x}^{(i)})$$

要最大似然估计，我们可以最小化似然的负对数：

$$
-\ln{P(\textbf{Y} \mid \textbf{X})} = \sum_{i=1}^n -\ln(P(\textbf{y}^{(i)} \mid \textbf{x}^{(i)})) = \sum_{i=1}^n l(\textbf{y}^{(i)}, \hat{\textbf{y}}^{(i)})$$

为了更直观地表示损失函数 $l(\textbf{y}, \hat{\textbf{y}})$ ，我们希望能用关于 $\textbf{y}$ 和 $\hat{\textbf{y}}$ 的式子来表示 $P(\textbf{y}^{(i)} \mid \textbf{x}^{(i)})$ 。考虑到 $\textbf{y}$ 是一个长度为 $q$ 的独热编码，其中除了表示其正确类别的分量为 $1$ 以外其余分量都是$0$ ，因此可以考虑用如下方式表示：

$$
P(\textbf{y}^{(i)} \mid \textbf{x}^{(i)}) = \sum_{j=1}^q y_j \hat{y_j}$$

于是我们得到对任意一个样本的损失函数：

$$
l(\textbf{y}, \hat{\textbf{y}}) = -\sum_{j=1}^q y_j \ln(\hat{y_j})$$

当正确预测标签时，损失函数取到最小值 $0$ ，符合需求。

这个损失函数实际上称为<em>交叉熵损失</em>，它是分类问题最常用的损失之一。有关熵和交叉熵损失的内容将在 4.5 节中简单展开。

### softmax 及其导数

根据 $\text{softmax}$ 函数定义，可得

$$
\begin{align} l(\textbf{y}, \hat{\textbf{y}}) &= -\sum_{j=1}^q y_j \ln(\frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)}) \\  &= \sum_{j=1}^q y_j \ln{\sum_{k=1}^q \exp(o_k)} - \sum_{j=1}^q y_j o_j \\  &= \ln{\sum_{k=1}^q \exp(o_k)} - \sum_{j=1}^q y_j o_j \end{align}$$

将它对 $o_j$ 求导，得

$$\partial_{o_j} l(\textbf{y}, \hat{\textbf{y}}) = \frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} - y_j = \text{softmax}(\textbf{o})_j - y_j$$

可以看到这一结构与线性回归中损失函数的导数非常相似。

## 信息论基础

### 信息量与熵

在信息论中，<em>熵</em>是接收的每条消息中包含的信息的平均量，又被称为信息熵、信源熵、平均自信息量。这里，“消息”代表来自分布或数据流中的事件、样本或特征。值域为 $\{x_1, \dots , x_n\}$ 的随机变量 $X$ 熵的计算式如下，它表示的是对随机变量 $X$ 的信息量的期望值：

$$
H(X) = E[I(X)] = \sum_i P(x_i)I(x_i) = -\sum_i P(x_i) \log_b{P(x_i)}$$

在这里 $b$ 是对数所使用的底，通常是 $2$ ，自然常数 $e$ ，或是 $10$ 。当 $b = 2$ ，熵的单位是 bit ；当 $b = e$ ，熵的单位是 nat ；而当 $b = 10$ ，熵的单位是 Hart 。信息论的基本定理之一指出，为了对从分布为 $P$ 的随机变量 $X$ 中随机抽取的数据进行编码，我们至少需要 $H(X)$ 的消息长度对其进行编码。

在上式中， $I(x)$ 表示 $x$ 的信息量，其计算式为

$$
I(x) = -\log_b{P(x)}$$

我们以抛硬币为例。如果有一枚理想的硬币，其出现正面和反面的机会相等，我们无法预测下一次硬币抛掷的结果。在这种情况下，抛一次硬币的信息量就是 $-\log_b \frac12$ 。假设取 $b = 2$ ，则信息量为 $1$ ，熵为 $1$ ，也就是需要一比特的消息长度来对一次硬币的结果进行编码（$0$ 或 $1$）。而如果现在有另外一枚硬币，它的两面完全相同，则这种情况下抛一次硬币的信息量就是 $-\log_b 1 = 0$ ，熵也为 $0$ ，因为结果可以被准确预测，“下一次抛掷的结果为xxx”毫无信息。

### 相对熵

- [推荐资料：KL散度(Kullback-Leibler Divergence)介绍及详细公式推导](https://hsinjhao.github.io/2019/05/22/KL-DivergenceIntroduction/)

<em>KL散度</em> ，又称<em>相对熵</em>，是两个概率分布 $P$ 和 $Q$ 差别的非对称性的度量，它是用来度量使用基于 $Q$ 的分布来编码服从 $P$ 的分布的样本所需的额外的平均比特数。典型情况下， $P$ 表示数据的真实分布， $Q$ 表示数据的理论分布、估计的模型分布、或 $P$ 的近似分布。而在机器学习中，或者更具体的，在本节所讲述的情况下， $P$ 用来表示样本的真实概率标签，即一个独热编码向量； $Q$ 用来表示模型所预测的概率向量。一个对这种情况下的相对熵直观的理解是，用 $Q$ 来描述样本，只能大致描述，但不是精确的，因此在信息量上比 $P$ 少，需要额外补充大小为相对熵 $D_{KL}(P||Q)$ 的信息增量才能准确描述。相对熵越小，则 $Q$ 的预测结果越好。

相对熵的计算公示为：

$$
D_{KL}(P||Q) = \sum_i P(x_i)\log_b{\frac{P(x_i)}{Q(x_i)}}$$

### 交叉熵

对相对熵的计算式变形可得：

$$
\begin{align} D_{KL}(P||Q) &= \sum_i P(x_i) \log_b{P(x_i)} - \sum_i P(x_i) \log_b{Q(x_i)} \\  &= -H(P) + [- \sum_i P(x_i) \log_b{Q(x_i)}] \end{align}$$

等号右边的第二项就是 $P$ 和 $Q$ 的交叉熵，用 $H(P, Q)$ 表示。上式移项后可得：

$$
H(P, Q) = H(P) + D_{KL}(P||Q)$$

即 $P$ 与 $Q$ 的交叉熵大小等于 $P$ 的熵加上 $P$ 与 $Q$ 的相对熵。在本例中，由于样本的概率分布是确定的，故根据交叉熵的大小即可衡量相对熵的大小。这就是交叉熵损失函数优化模型的原理。

综上，交叉熵损失函数可从两个角度理解：(1) 最大化似然 (2) 最小化相对熵。

# 图像分类数据集

机器学习离不开数据集的使用，本节将简单介绍通过 pytorch 下载和使用 Fashion-MNIST 数据集。

## 导入相关库

```py
import torch
import torchvision
from torch.utils import data
from torchvision import transforms
from d2l import torch as d2l
```

## 下载数据集

torchvision 库中内置了 Fashion-MNIST 数据集的下载函数 `torchvision.datasets.FashionMNIST()` ，可通过这个函数将数据集下载并读取到内存中。

```py
trans = transforms.ToTensor()
mnist_train = torchvision.datasets.FashionMNIST(
    root="../data", train=True, transform=trans, download=True)
mnist_test = torchvision.datasets.FashionMNIST(
    root="../data", train=False, transform=trans, download=True)
```

这里用到了 `torchvision.transforms.ToTensor()` 函数作为下载函数的 `transform` 参数，原因是下载样本的默认格式是 PIL 图片格式，这个函数将把图像数据从 PIL 变换成 $[0, 1]$ 之间的 32 位浮点数。

因为网络原因直接通过这个函数下载可能会非常非常慢，这种情况下可以访问 [zalandoresearch / fashion-mnist](https://github.com/zalandoresearch/fashion-mnist/tree/master/data/fashion) 来手动下载四个数据包到指定目录，这样代码在运行的时候就会跳过下载直接解压。

## 数据集内容

Fashion-MNIST 由 10 个类别的图像组成， 每个类别由训练数据集中的 6000 张图像和测试数据集中的 1000 张图像组成。 因此，训练集和测试集分别包含 60000 和 10000 张图像。 测试数据集不会用于训练，只用于评估模型性能。每个输入图像均为 $28 \times 28$ 的灰度图像。

```py
print(mnist_train[0][0].shape)
```

```text
torch.Size([1, 28, 28])
```

Fashion-MNIST 中包含的 10 个类别，分别为 t-shirt（T恤）、trouser（裤子）、pullover（套衫）、dress（连衣裙）、coat（外套）、sandal（凉鞋）、shirt（衬衫）、sneaker（运动鞋）、bag（包）和ankle boot（短靴）。 以下函数用于在数字标签索引及其文本名称之间进行转换。

```py
def get_fashion_mnist_labels(labels):
    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',
                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']
    return [text_labels[int(i)] for i in labels]
```

这里我们可以用一个函数来可视化这些图片数据。函数主要部分就是利用 `d2l.plt` 来实现数据信息到可视化图片的过程。

```py
def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):
    figsize = (num_cols * scale, num_rows * scale)
    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)
    axes = axes.flatten()
    for i, (ax, img) in enumerate(zip(axes, imgs)):
        if torch.is_tensor(img):
            # 图片张量
            ax.imshow(img.numpy())
        else:A
            # PIL图片
            ax.imshow(img)
        # 隐藏座标轴
        ax.axes.get_xaxis().set_visible(False)
        ax.axes.get_yaxis().set_visible(False)
        if titles:
            ax.set_title(titles[i])
    return axes
```

我们可以试着显示训练集中的前 18 个样本及其对应的标签。

```py
X, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))
show_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y))
```

![](/assets/RZIub7xZZoPLgZxZyT6coOdCnyd.png)

## 读取数据集

在第 3 节和第 5.3 节中我们都用到了 `data.DataLoader` 来实现数据迭代器。事实上，对这个类我们还可以通过 `num_workers` 参数指定读取数据所用的进程数。如下是一个典型的训练集读取方式：

```py
batch_size = 256

def get_dataloader_workers():
    return 4

train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,
     num_workers=get_dataloader_workers())
```

## 整合所有组件

下面将把上述有关组件整合起来，展示一个简单的获取和读取 Fashion-MNIST 数据集的函数。

```py
def load_data_fashion_mnist(batch_size, resize=None):
    """下载Fashion-MNIST数据集，然后将其加载到内存中"""
    trans = [transforms.ToTensor()]
    if resize:
        # 图像大小缩放
        trans.insert(0, transforms.Resize(resize))
    trans = transforms.Compose(trans)
    mnist_train = torchvision.datasets.FashionMNIST(
        root="../data", train=True, transform=trans, download=True)
    mnist_test = torchvision.datasets.FashionMNIST(
        root="../data", train=False, transform=trans, download=True)
    return (data.DataLoader(mnist_train, batch_size, shuffle=True,
                            num_workers=get_dataloader_workers()),
            data.DataLoader(mnist_test, batch_size, shuffle=False,
                            num_workers=get_dataloader_workers()))
    
train_iter, test_iter = load_data_fashion_mnist(32, resize=64)
for X, y in train_iter:
    print(X.shape, X.dtype, y.shape, y.dtype)
    break
```

```go
torch.Size([32, 1, 64, 64]) torch.float32 torch.Size([32]) torch.int64
```

可以看到 $X$ 为 32 个单通道 $64 \times 64$ 的图片数据，$Y$ 为 $32$ 个标签数据。

# softmax 回归的从零开始实现

## 导入相关库

```py
import torch
from IPython import display
from d2l import torch as d2l
```

## 初始化数据集

在 5.5 节中用到的的 `load_data_fashion_mnist` 函数已经在 `d2l` 库中定义，我们可以直接调用该函数来实现 Fashion-MNIST 数据集的下载和初始化。

```py
batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
```

## 初始化模型参数

在第 3 节线性回归的实现中，我们用一个一维向量来表示一个数据样本。对于本例中的图片样本也一样。原始数据集中的样本是 $28 \times 28$ 的灰度图，这里我们将它展平为一个长为 784 的一维向量。

考虑第 4 节中讲述的分类问题的方程。方程的个数与类别数相等，每个方程中都有数量等同于样本特征数的权重以及一个偏置。对于 Fashion-MNIST 数据集，类别数为 10 ，样本特征数为 784 ，故权重矩阵大小为 $784 \times 10$ ，偏置矩阵大小为 $1 \times 10$ 。与线性回归一样，我们将使用正态分布初始化我们的权重 $\textbf{W}$ ，偏置初始化为 0 。

```py
num_inputs = 784
num_outputs = 10

W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)
b = torch.zeros(num_outputs, requires_grad=True)
```

## 定义 softmax 操作

根据几个参数矩阵大小的规定，我们通过矩阵乘法得到的 $\textbf{o}$ 矩阵大小应该为 $\text{样本数} \times 10$ 。由此，实现 softmax 运算的步骤如下：

1. 对每一项求幂
2. 对每一行求和，得到每个样本的规范化常数
3. 对每一项除以其所在行对应的规范化常数

即如下表达式：

$$
\text{softmax}(\textbf{o})_{ij} = \frac{\exp(\textbf{o}_{ij})}{\sum_k \exp(\textbf{o}_{ik})}$$

于是可以定义如下 softmax 函数：

```py
def softmax(o):
    o_exp = torch.exp(o)
    partition = o_exp.sum(1, keepdim=True)
    return o_exp / partition
```

注意，虽然这在数学上看起来是正确的，但我们在代码实现中有点草率。 矩阵中的非常大或非常小的元素可能造成数值上溢或下溢，但我们没有采取措施来防止这点。这一部分的优化将在 7.1 中简单展开。

## 定义模型

在定义了参数及 softmax 函数后，我们就可以定义 softmax 回归的模型了，也就是如下关系：

$$
\hat{\textbf{y}} = \text{softmax}(\textbf{Xw} + \textbf{b})$$

```py
def net(X):
    return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b)
```

这里通过 `reshape` 函数将原始的图像数据展开为一维向量。

## 定义损失函数

在 4.4 和 4.5 两小节中我们介绍了交叉熵损失函数，这也是我们将实现的损失函数。值得一提的是，这里我们不使用 for 循环来遍历，而是通过 range 来实现所有元素的选择。

```py
def cross_entropy(y_hat, y):
    return - torch.log(y_hat[range(len(y_hat)), y])
```

## 分类精度

对于模型输出的概率分布 $\hat{\textbf{y}}$ ，当我们需要对样本做出硬预测时，我们通常会选择概率最高的那一类。当预测与标签分类一致时，预测正确。分类精度即正确预测数量与总预测数量之比。精度通常是我们最关心的性能衡量标准，我们在训练分类器时几乎总会关注它。而不选择分类精度作为损失函数主要是由于精度的计算不可导，很难直接优化。

为了计算精度，我们执行以下操作。由于 softmax 操作不改变矩阵大小，因此精度计算函数的操作对象大小仍然是 $\text{样本数} \times 10$ ，即第二个维度存储每个类的预测概率。因此我们可以使用 `argmax` 来获得每行中最大元素的索引来预测其类别，然后使用 `==` 运算符来得到一个结果仅包含 0 / 1 的向量。对这个向量求和即可得到正确预测的数量。需要注意的是 `==` 运算符对类型敏感，因此我们要将 `y_hat` 的数据类型转化为与 `y` 一致。

```py
def accuracy(y_hat, y):
    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:
        y_hat = y_hat.argmax(axis=1)
    cmp = y_hat.type(y.dtype) == y
    return float(cmp.type(y.dtype).sum())
```

由于程序中会多次用到像记录正确预测个数这样的计数需求，我们定义一个类 `Accumulator` 用于计数。一个 `Accumulator` 实例中包含 n 个变量，分别表示一个我们需要进行计数的对象。

```py
class Accumulator:
    """在n个变量上累加"""
    def __init__(self, n):
        self.data = [0.0] * n

    def add(self, <em>args):
        self.data = [a + float(b) for a, b in zip(self.data, args)]

    def reset(self):
</em><em>        self.data = [0.0] </em> len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]
```

利用 `accuracy` 函数和 `Accumulator` 对象，我们便可以实现对指定数据集的分类精度的计算。

```py
def evaluate_accuracy(net, data_iter):
    if isinstance(net, torch.nn.Module):
        net.eval()  # 将模型设置为评估模式
    metric = Accumulator(2)  # 正确预测数、预测总数
    with torch.no_grad():
        for X, y in data_iter:
            metric.add(accuracy(net(X), y), y.numel())
    return metric[0] / metric[1]
```

## 训练

softmax 回归的训练函数和线性回归非常相似，这里不赘述，仅在关键部分加以注释。

```py
def train_epoch_ch3(net, train_iter, loss, updater):
    # 将模型设置为训练模式
    if isinstance(net, torch.nn.Module):
        net.train()
    # 训练损失总和、训练准确度总和、样本数
    metric = Accumulator(3)
    for X, y in train_iter:
        # 计算梯度并更新参数
        y_hat = net(X)
        l = loss(y_hat, y)
        if isinstance(updater, torch.optim.Optimizer):
            # 使用PyTorch内置的优化器和损失函数
            updater.zero_grad()
            l.mean().backward()
            # 内置优化器不包含除以 batch_size 部分，故损失函数的结果取均值
            updater.step()
        else:
            # 使用自定义的优化器和损失函数
            l.sum().backward()
            updater(X.shape[0])
            # 自定义优化器含除以 batch_size ，故损失函数的结果取和
        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())
    # 返回训练损失和训练精度
    return metric[0] / metric[2], metric[1] / metric[2]
```

我们可以定义一个 `Animator` 类用于动态展现每一步优化的结果。

```py
class Animator:
    """在动画中绘制数据"""
    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,
                 ylim=None, xscale='linear', yscale='linear',
                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,
                 figsize=(3.5, 2.5)):
        # 增量地绘制多条线
        if legend is None:
            legend = []
        d2l.use_svg_display()
        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)
        if nrows * ncols == 1:
            self.axes = [self.axes, ]
        # 使用lambda函数捕获参数
        self.config_axes = lambda: d2l.set_axes(
            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)
        self.X, self.Y, self.fmts = None, None, fmts

    def add(self, x, y):
        # 向图表中添加多个数据点
        if not hasattr(y, "__len__"):
            y = [y]
        n = len(y)
        if not hasattr(x, "__len__"):
            x = [x] * n
        if not self.X:
            self.X = [[] for _ in range(n)]
        if not self.Y:
            self.Y = [[] for _ in range(n)]
        for i, (a, b) in enumerate(zip(x, y)):
            if a is not None and b is not None:
                self.X[i].append(a)
                self.Y[i].append(b)
        self.axes[0].cla()
        for x, y, fmt in zip(self.X, self.Y, self.fmts):
            self.axes[0].plot(x, y, fmt)
        self.config_axes()
        display.display(self.fig)
        display.clear_output(wait=True)
```

有了单次训练函数和过程绘制类，我们便可以将它们组合成多轮次的训练函数。该训练函数将会运行多个迭代周期（由`num_epochs`指定）。 在每个迭代周期结束时，利用`test_iter`访问到的测试数据集对模型进行评估。

```py
def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):
    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],
                        legend=['train loss', 'train acc', 'test acc'])
    for epoch in range(num_epochs):
        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)
        test_acc = evaluate_accuracy(net, test_iter)
        animator.add(epoch + 1, train_metrics + (test_acc,))
    train_loss, train_acc = train_metrics
    assert train_loss < 0.5, train_loss
    assert train_acc <= 1 and train_acc > 0.7, train_acc
    assert test_acc <= 1 and test_acc > 0.7, test_acc
```

对于优化器，我们仍然使用第 2 节所定义的 `sgd` 函数（该函数包含在 `d2l` 包内）。

```py
lr = 0.1

def updater(batch_size):
    return d2l.sgd([W, b], lr, batch_size)
```

现在我们进行 10 轮的训练。

```py
num_epochs = 10
train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)
```

训练进度的可视化结果如下：

![](/assets/NopRbOy1EoCom5xrMz0ctqyanUe.gif)

## 预测

模型训练的最终目的是预测。现在，我们使用测试数据集中的数据来检验模型在未知数据上的表现。这里我们将预测结果的前 6 项进行可视化，他们的实际标签在文本第一行，模型预测结果在文本第二行。

```py
def predict_ch3(net, test_iter, n=6):
    for X, y in test_iter:
        break
    trues = d2l.get_fashion_mnist_labels(y)
    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))
    titles = [true +'\n' + pred for true, pred in zip(trues, preds)]
    d2l.show_images(
        X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n])

predict_ch3(net, test_iter)
```

可视化结果如下：

![](/assets/MbeDbjlxCoJOyixu8k3cVBvon2c.png)

## 完整代码

```py
import torch
from IPython import display
from d2l import torch as d2l

def softmax(o):
    o_exp = torch.exp(o)
    partition = o_exp.sum(1, keepdim=True)
    return o_exp / partition

def net(X):
    return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b)

def cross_entropy(y_hat, y):
    return - torch.log(y_hat[range(len(y_hat)), y])

def accuracy(y_hat, y):
    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:
        y_hat = y_hat.argmax(axis=1)
    cmp = y_hat.type(y.dtype) == y
    return float(cmp.type(y.dtype).sum())

class Accumulator:
    def __init__(self, n):
        self.data = [0.0] * n

    def add(self, *args):
        self.data = [a + float(b) for a, b in zip(self.data, args)]

    def reset(self):
        self.data = [0.0] * len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]

def evaluate_accuracy(net, data_iter):
    if isinstance(net, torch.nn.Module):
        net.eval()
    metric = Accumulator(2)
    with torch.no_grad():
        for X, y in data_iter:
            metric.add(accuracy(net(X), y), y.numel())
    return metric[0] / metric[1]

class Animator:
    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,
                 ylim=None, xscale='linear', yscale='linear',
                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,
                 figsize=(3.5, 2.5)):
        if legend is None:
            legend = []
        d2l.use_svg_display()
        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)
        if nrows * ncols == 1:
            self.axes = [self.axes, ]
        self.config_axes = lambda: d2l.set_axes(
            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)
        self.X, self.Y, self.fmts = None, None, fmts

    def add(self, x, y):
        if not hasattr(y, "__len__"):
            y = [y]
        n = len(y)
        if not hasattr(x, "__len__"):
            x = [x] * n
        if not self.X:
            self.X = [[] for _ in range(n)]
        if not self.Y:
            self.Y = [[] for _ in range(n)]
        for i, (a, b) in enumerate(zip(x, y)):
            if a is not None and b is not None:
                self.X[i].append(a)
                self.Y[i].append(b)
        self.axes[0].cla()
        for x, y, fmt in zip(self.X, self.Y, self.fmts):
            self.axes[0].plot(x, y, fmt)
        self.config_axes()
        display.display(self.fig)
        display.clear_output(wait=True)

def train_epoch_ch3(net, train_iter, loss, updater):
    if isinstance(net, torch.nn.Module):
        net.train()
    metric = Accumulator(3)
    for X, y in train_iter:
        y_hat = net(X)
        l = loss(y_hat, y)
        if isinstance(updater, torch.optim.Optimizer):
            updater.zero_grad()
            l.mean().backward()
            updater.step()
        else:
            l.sum().backward()
            updater(X.shape[0])
        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())
    return metric[0] / metric[2], metric[1] / metric[2]

def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):
    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],
                        legend=['train loss', 'train acc', 'test acc'])
    for epoch in range(num_epochs):
        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)
        test_acc = evaluate_accuracy(net, test_iter)
        animator.add(epoch + 1, train_metrics + (test_acc,))
    train_loss, train_acc = train_metrics
    assert train_loss < 0.5, train_loss
    assert train_acc <= 1 and train_acc > 0.7, train_acc
    assert test_acc <= 1 and test_acc > 0.7, test_acc

lr = 0.1

def updater(batch_size):
    return d2l.sgd([W, b], lr, batch_size)

batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)

num_inputs = 784
num_outputs = 10

W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)
b = torch.zeros(num_outputs, requires_grad=True)

num_epochs = 10
train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)

def predict_ch3(net, test_iter, n=6):
    for X, y in test_iter:
        break
    trues = d2l.get_fashion_mnist_labels(y)
    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))
    titles = [true +'\n' + pred for true, pred in zip(trues, preds)]
    d2l.show_images(
        X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n])

predict_ch3(net, test_iter)
```

# softmax 回归的简洁实现

和线性回归一样，通过调用深度学习框架的 api 也能简化 softmax 回归的实现。这里我们将首先简单讲述 pytorch 中的交叉熵损失函数，再附上第 6 节中代码的简洁版本。

## 重新审视 softmax 的实现

在第 6 节中，我们将未规范化的预测输入 softmax 函数中进行计算，再将结果提供给交叉熵损失函数。这在数学上看起来很合理。然而，从计算角度来看，指数可能会造成数值稳定性问题。考虑到 softmax 函数的形式 $\hat{y_j} = \frac{\exp(o_j)}{\sum_k \exp(o_k)}$ ，如果 $o_k$ 中的一些数值较大，那么经过指数计算后可能会超出数据类型所能容许的上限，即上溢。解决这个问题的一个办法是，在输入 softmax 函数之前，先从所有的 $o_k$ 中减掉 $\max{o_k}$ 。根据如下推导可知，这不改变 softmax 函数的结果。

$$
\begin{align} \hat{y_j} &= \frac{\exp(o_j)}{\sum_k \exp(o_k)} \\  &= \frac{\exp(o_j - \max{o_k}) \cdot \exp(\max{o_k})}{\sum_k \exp(o_k - \max{o_k}) \cdot \exp(\max{o_k})} \\  &= \frac{\exp(o_j - \max{o_k})}{\sum_k \exp(o_k - \max{o_k})} \end{align}$$

这一操作又可能引入新的问题。 $o_j - \max{o_k}$ 可能会具有较大的负值，在经过指数运算和除法运算后，由于精度问题，可能会使 $\hat{y_j}$ 为 0 。这将导致在交叉熵损失函数中的 $\log{\hat{y_j}}$ 的值为 $-\inf$ 。为了避免这个指数运算带来的数值稳定性问题，我们可以考虑将 softmax 和交叉熵结合在一起，将 softmax 中的 $\exp$ 运算与交叉熵中的 $\log$ 运算抵消，即：

$$
\begin{align} \log{\hat{y_j}} &= \log{\frac{\exp(o_j - \max{o_k})}{\sum_k \exp(o_k - \max{o_k})}} \\ &= \log{\exp(o_j - \max{o_k})} - \log{\sum_k \exp(o_k - \max{o_k})} \\ &= o_j - \max{o_k} - \log{\sum_k \exp(o_k - \max{o_k})} \end{align}$$

pytorch 中的交叉熵损失函数实现的就是这个过程。我们可以简单的通过如下代码来调用：

```py
loss = nn.CrossEntropyLoss(reduction='none')
```

## 简洁实现代码

```py
import torch
from torch import nn
from d2l import torch as d2l

def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)

batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)

net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))
# PyTorch不会隐式地调整输入的形状。因此，
# 我们在线性层前定义了展平层（flatten），来调整网络输入的形状
net.apply(init_weights)

loss = nn.CrossEntropyLoss(reduction='none')
trainer = torch.optim.SGD(net.parameters(), lr=0.1)

num_epochs = 10
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
```

训练过程可视化结果如下：

![](/assets/XyJnb5uUCoK8DRxdEflcQtsKnrc.gif)

---

# 注意力提示

## 生物学中的注意力提示

生物学上认为注意力系统由双组件框架构成，在这个框架中，焦点引导由<em>非自主性提示</em>和<em>自主性提示</em>来完成。

非自主性提示主要由客观环境中物体的突出性来表现。例如我们面前有黑白印刷的报纸、研究论文、笔记本和书，以及一个红色的咖啡杯。很显然，在这个环境中咖啡杯是最突出和显眼的，所以我们会把视力最敏锐的地方放在咖啡上。

自主性提示主要由人的主观意识推动。同样还是上面的例子，但现在你有论文复现的 ddl 要赶，那么你的视线就会聚焦于研究论文上。此时选择论文就是受到了认知和意识的控制。

## 查询、键和值

对于上述生物学中的注意力系统，我们尝试用一个数学模型来表达它，以此实现在计算机中实现神经网络中的注意力机制。

在我们尝试搭建的模型中，我们将一个物体在系统中的输入称为<em>值</em>，注意力聚焦的过程也就是从这些值中选择一个。每一个物体对应一些特征、线索，我们将这些非意志线索称为<em>键</em>。每一个值都对应了一个键。可以想到的是，在注意力机制的背景下，是否有自主性提示是一个很重要的“开关”。我们将自主性提示称为<em>查询</em>。对这套系统，我们主要需要设计的是注意力汇聚部分，通过这一部分，我们实现对于给定的查询，与键进行匹配，引导出最匹配的值。

![](/assets/DLUjbTD6roWnAxxq59tcRdLwnTd.png)

## 注意力的可视化

注意力的数学实现实际是对值的加权平均数，其中权重是在给定的查询和不同的键之间得到的。我们可以定义一个函数来可视化这个权重矩阵。

```py
def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5),
                  cmap='Reds'):
    d2l.use_svg_display()
    num_rows, num_cols = matrices.shape[0], matrices.shape[1]
    fig, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize,
                                 sharex=True, sharey=True, squeeze=False)
    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):
        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):
            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)
            if i == num_rows - 1:
                ax.set_xlabel(xlabel)
            if j == 0:
                ax.set_ylabel(ylabel)
            if titles:
                ax.set_title(titles[j])
    fig.colorbar(pcm, ax=axes, shrink=0.6)
```

下面使用一个简单的例子进行演示。 在本例子中，仅当查询和键相同时，注意力权重为1，否则为0。

```py
attention_weights = torch.eye(10).reshape((1, 1, 10, 10))
show_heatmaps(attention_weights, xlabel='Keys', ylabel='Queries')
```

![](/assets/Eq4VbNfatoAXdvxWsFTcwoOfnRd.png)

# 注意力汇聚：Nadaraya-Watson 核回归

我们思考一个简单的回归问题：对于给定的成对的“输入-输出”数据集 $\{(x_1, y_1), \ldots, (x_n, y_n)\}$ ，如何学习得到 $x$ 和 $y$ 之间的预测函数 $\hat{y} = f(x)$ ？在之前的学习中，我们会考虑使用线性回归的方法来拟合；这里，我们尝试用注意力机制来解决。

## 生成数据集

我们首先利用如下非线性函数生成一个带噪声 $\epsilon \sim \mathcal{N}(0, 0.5)$ 的人工数据集。

$$
y_i = 2\sin{x_i} + x_i^{0.8} + \epsilon$$

```py
n_train = 50  # 训练样本数
x_train, _ = torch.sort(torch.rand(n_train) * 5)   # 排序后的训练样本

def f(x):
    return 2 * torch.sin(x) + x**0.8

y_train = f(x_train) + torch.normal(0.0, 0.5, (n_train,))  # 训练样本的输出
x_test = torch.arange(0, 5, 0.1)  # 测试样本
y_truth = f(x_test)  # 测试样本的真实输出
n_test = len(x_test)  # 测试样本数
```

这里我们排序是为了后续更好地进行注意力热图绘制。

将生成的数据在图上标注，样本用圆圈表示，不带噪声的生成函数 $f$ 用曲线表示：

```py
def plot_kernel_reg(y_hat):
    d2l.plot(x_test, y_truth, 'x', 'y', legend='Truth',
             xlim=[0, 5], ylim=[-1, 5])
    d2l.plt.plot(x_train, y_train, 'o', alpha=0.5)
```

![](/assets/GG4jb3LVCoOsiKxaGxGcVqhQnTf.png)

## 平均汇聚

在 1.3 中我们曾演示过一个简单的注意力矩阵，即单位矩阵，当且仅当查询和键相同时，注意力权重为1，否则为0。这里我们用另一个简单的矩阵来试着解决这个问题：平均矩阵。即对所有数据的注意力相同，通过平均汇聚来计算所有样本输出值的平均值：

$$
f(x) = \frac1n \sum_{i=1}^n y_i$$

我们用这个函数来对测试数据进行预测，将结果绘制在图中。

```py
def plot_kernel_reg(y_hat):
    d2l.plot(x_test, [y_truth, y_hat], 'x', 'y', legend=['Truth', 'Pred'],
             xlim=[0, 5], ylim=[-1, 5])
    d2l.plt.plot(x_train, y_train, 'o', alpha=0.5)
    
y_hat = torch.repeat_interleave(y_train.mean(), n_test)
plot_kernel_reg(y_hat)
```

![](/assets/GplUbIcwtoKWVLx6dbTc0SdfnIh.png)

很显然，这种估计方式表现不好。

## 非参数注意力汇聚

平均汇聚的问题在于它忽略了输入 $x_i$ 。于是我们可以考虑如何把输入纳入注意力范围。一个直观地想法是，测试数据输入 x 距离一个训练数据输入 $x_i$ 越近，那么我们应该给予这个训练数据更多的注意力。也就是说，可以将平均改为基于距离的加权平均：

$$
f(x) = \sum_{i=1}^n \frac{K(x - x_i)}{\sum_{j=1}^n K(x - x_j)} y_i$$

其中 $K$ 是核，用于描述 $x$ 到 $x_i$ 之间的距离。上面这个公示被称为 <em>Nadaraya-Watson 核回归</em> 。

我们以高斯核为例：

$$
K(u) = \frac{1}{\sqrt{2\pi}} \exp{(-\frac{u^2}{2})}$$

将其带入可得：

$$
\begin{align} f(x) &= \sum_{i=1}^n \frac{\exp{(-\frac12 (x - x_i)^2)}}{\sum_{j=1}^n \exp{(-\frac12 (x - x_j)^2)}} y_i \\ &= \sum_{i=1}^n \text{softmax}(-\frac12 (x - x_i)^2) y_i \end{align}$$

这个过程中没有可学习参数的存在，因此这种模型是一个非参数的注意力汇聚模型。我们试着用这个模型来解决开头提出的问题。

```py
# X_repeat的形状:(n_test,n_train),
# 每一行都包含着相同的测试输入（例如：同样的查询）
X_repeat = x_test.repeat_interleave(n_train).reshape((-1, n_train))
# x_train包含着键。attention_weights的形状：(n_test,n_train),
# 每一行都包含着要在给定的每个查询的值（y_train）之间分配的注意力权重
attention_weights = nn.functional.softmax(-(X_repeat - x_train)**2 / 2, dim=1)
# y_hat的每个元素都是值的加权平均值，其中的权重是注意力权重
y_hat = torch.matmul(attention_weights, y_train)
plot_kernel_reg(y_hat)
```

![](/assets/AxuxbDkx9omF3axHkOqcGJUrnUb.png)

从绘制的结果会发现新的模型预测线是平滑的，并且比平均汇聚的预测更接近真实。

我们用之前定义的注意力热图绘制函数来把这里生成的注意力矩阵绘制出来观察。

```py
d2l.show_heatmaps(attention_weights.unsqueeze(0).unsqueeze(0),
                  xlabel='Sorted training inputs',
                  ylabel='Sorted testing inputs')
```

![](/assets/AZrGbepMvo7FQlxOnngcShkvnSf.png)

可以看到，查询和键的距离越近，注意力权重越大。

## 带参数的注意力汇聚

上一节中的模型叫非参数注意力汇聚，那么很显然，我们可以考虑在模型中加入可学习的参数，来实现带参数的注意力汇聚模型。例如，我们在查询和键的距离计算后加入可学习参数 $w$ ：

$$
\begin{align} f(x) &= \sum_{i=1}^n \frac{\exp{(-\frac12 (w(x - x_i))^2)}}{\sum_{j=1}^n \exp{(-\frac12 (w(x - x_j))^2)}} y_i \\ &= \sum_{i=1}^n \text{softmax}(-\frac12 (w(x - x_i))^2) y_i \end{align}$$

接下来的过程就是参数的学习过程。

### 定义模型

根据上面的式子，我们可以定义如下模型：

```py
class NWKernelRegression(nn.Module):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.w = nn.Parameter(torch.rand((1,), requires_grad=True))

    def forward(self, queries, keys, values):
        # queries和attention_weights的形状为(查询个数，“键－值”对个数)
        queries = queries.repeat_interleave(keys.shape[1]).reshape((-1, keys.shape[1]))
        self.attention_weights = nn.functional.softmax(
            -((queries - keys) * self.w)**2 / 2, dim=1)
        # values的形状为(查询个数，“键－值”对个数)
        return torch.bmm(self.attention_weights.unsqueeze(1),
                         values.unsqueeze(-1)).reshape(-1)
```

### 训练

接下来我们使用训练数据来进行参数的学习。值得一提的是，这里我们对于每一个训练样本，在训练计算时都将自己排除在外，即每一个一个训练样本的输入都会和除自己以外的所有训练样本的“键－值”对进行计算，这样可以有效地降低过拟合问题。

```py
# X_tile的形状:(n_train，n_train)，每一行都包含着相同的训练输入
X_tile = x_train.repeat((n_train, 1))
# Y_tile的形状:(n_train，n_train)，每一行都包含着相同的训练输出
Y_tile = y_train.repeat((n_train, 1))
# keys的形状:('n_train'，'n_train'-1)
keys = X_tile[(1 - torch.eye(n_train)).type(torch.bool)].reshape((n_train, -1))
# values的形状:('n_train'，'n_train'-1)
values = Y_tile[(1 - torch.eye(n_train)).type(torch.bool)].reshape((n_train, -1))
```

我们使用平方损失函数和随机梯度下降来进行参数的学习。

```py
net = NWKernelRegression()
loss = nn.MSELoss(reduction='none')
trainer = torch.optim.SGD(net.parameters(), lr=0.5)

for epoch in range(5):
    trainer.zero_grad()
    l = loss(net(x_train, keys, values), y_train)
    l.sum().backward()
    trainer.step()
    print(f'epoch {epoch + 1}, loss {float(l.sum()):.6f}')
```

```text
epoch 1, loss 45.573853
epoch 2, loss 28.077816
epoch 3, loss 28.006203
epoch 4, loss 27.932493
epoch 5, loss 27.856602
```

我们可以再次把拟合出来的曲线进行绘制。

```py
# keys的形状:(n_test，n_train)，每一行包含着相同的训练输入（例如，相同的键）
keys = x_train.repeat((n_test, 1))
# value的形状:(n_test，n_train)
values = y_train.repeat((n_test, 1))
y_hat = net(x_test, keys, values).unsqueeze(1).detach()
plot_kernel_reg(y_hat)
```

![](/assets/DITebdo8lotofaxXwtfcK7Hrnzu.png)

可以看到，与之前的非参数模型相比，曲线不平滑了许多，这是由于可学习参数的加入使模型对数据的过拟合程度加重了。我们也可以通过绘制注意力矩阵来查看。

![](/assets/ObhybMKzWoyUjqxg6M2cVNiinMb.png)

可以看到注意力矩阵在权重较大的部分也相对更不平滑。

# 注意力评分函数

在第 2 节中我们介绍了高斯核，我们可以看到它的作用是描述查询到键之间的距离。我们把高斯核的指数部分视为注意力评分函数，简称评分函数。用数学语言表示，即

$$
\alpha(\textbf{q}, \textbf{k}_i) = \text{softmax}(a(\textbf{q}, \textbf{k}_i)) = \sum_{i=1}^n \frac{\exp{a(\textbf{q}, \textbf{k}_i)}}{\sum_{j=1}^n \exp{a(\textbf{q}, \textbf{k}_i)}}$$

其中 $a(\textbf{q}, \textbf{k}_i)$ 即评分函数。除了高斯核的指数部分，还有许多其他类型的评分函数。这里将介绍其中两个。

## 掩蔽 softmax 操作

在具体介绍评分函数之前我们先来考虑我们熟悉的 softmax 操作。在上一节中我们看到，softmax 操作可以用于输出一个概率分布作为注意力权重。但是一些特殊情况下，并非所有的键值对都应纳入考虑，例如文本处理模型中的无意义填充词元。基于这种情况，我们可以通过指定序列有效长度来把超过长度的无效内容过滤掉。这种改进的操作叫做遮蔽 softmax 操作。

```py
def masked_softmax(X, valid_lens):
    """通过在最后一个轴上掩蔽元素来执行softmax操作"""
    # X:3D张量，valid_lens:1D或2D张量
    if valid_lens is None:
        return nn.functional.softmax(X, dim=-1)
    else:
        shape = X.shape
        if valid_lens.dim() == 1:
            valid_lens = torch.repeat_interleave(valid_lens, shape[1])
        else:
            valid_lens = valid_lens.reshape(-1)
        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0
        X = d2l.sequence_mask(X.reshape(-1, shape[-1]), valid_lens,
                              value=-1e6)
        return nn.functional.softmax(X.reshape(shape), dim=-1)
```

## 加性注意力

如果查询和键的长度不同，可以考虑使用加性注意力作为评分函数。加性注意力评分函数为：

$$
a(\textbf{q}, \textbf{k}) = \textbf{w}_v^T \tanh{(\textbf{W}_q \textbf{q} + \textbf{W}_k \textbf{k})}$$

即将查询 $\textbf{q}$ 和键 $\textbf{k}$ 连接起来后输入到多层感知机中，多层感知机的隐藏单元数为超参数，并使用 $\tanh$ 作为激活函数。

```py
class AdditiveAttention(nn.Module):
    """加性注意力"""
    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):
        super(AdditiveAttention, self).__init__(**kwargs)
        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)
        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)
        self.w_v = nn.Linear(num_hiddens, 1, bias=False)
        self.dropout = nn.Dropout(dropout)

    def forward(self, queries, keys, values, valid_lens):
        queries, keys = self.W_q(queries), self.W_k(keys)
        # 在维度扩展后，
        # queries的形状：(batch_size，查询的个数，1，num_hidden)
        # key的形状：(batch_size，1，“键－值”对的个数，num_hiddens)
        # 使用广播方式进行求和
        features = queries.unsqueeze(2) + keys.unsqueeze(1)
        features = torch.tanh(features)
        # self.w_v仅有一个输出，因此从形状中移除最后那个维度。
        # scores的形状：(batch_size，查询的个数，“键-值”对的个数)
        scores = self.w_v(features).squeeze(-1)
        self.attention_weights = masked_softmax(scores, valid_lens)
        # values的形状：(batch_size，“键－值”对的个数，值的维度)
        return torch.bmm(self.dropout(self.attention_weights), values)
```

## 缩放点积注意力

当查询和键具有相同的向量长度 $d$ 时， 可以采用点积的方式来使计算效率更高。假设查询和键的所有元素都是独立的随机变量， 并且都满足零均值和单位方差， 那么两个向量的点积的均值为 $0$ 和 $d$ 。为确保无论向量长度如何， 点积的方差在不考虑向量长度的情况下仍然是 $1$ ， 我们再将点积除以 $\sqrt{d}$ ， 则<em>缩放点积注意力</em>评分函数为：

$$
a(\textbf{q}, \textbf{k}) = \frac{\textbf{q}^T \textbf{k}}{\sqrt{d}}$$

考虑到实践中通常会用到小批量数据，我们将式子改写为如下形式，其中 $n$ 为查询个数，$m$ 为键值对个数，$d$ 为查询和键的长度， $v$ 为值的长度，则有查询 $\textbf{Q} \in \mathbb{R}^{n \times d}$ ，键 $\textbf{K} \in \mathbb{R}^{m \times d}$ ，值 $\textbf{V} \in \mathbb{R}^{m \times v}$ ，缩放点积注意力：

$$
\text{softmax}(\frac{\textbf{Q}\textbf{K}^T}{\sqrt{d}}) \textbf{V}$$

下面的实现中用到了暂退法进行正则化。

```py
class DotProductAttention(nn.Module):
    """缩放点积注意力"""
    def __init__(self, dropout, **kwargs):
        super(DotProductAttention, self).__init__(**kwargs)
        self.dropout = nn.Dropout(dropout)

    # queries的形状：(batch_size，查询的个数，d)
    # keys的形状：(batch_size，“键－值”对的个数，d)
    # values的形状：(batch_size，“键－值”对的个数，值的维度)
    # valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)
    def forward(self, queries, keys, values, valid_lens=None):
        d = queries.shape[-1]
        # 设置transpose_b=True为了交换keys的最后两个维度
        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)
        self.attention_weights = masked_softmax(scores, valid_lens)
        return torch.bmm(self.dropout(self.attention_weights), values)
```

# Bahdanau 注意力

在之前的编码器-解码器结构中，我们注意到在解码过程中使用的上下文变量都是一样的——即使并非所有的输入词元都对某一个词元的解码有用。于是，我们可以考虑通过注意力机制，来将模型上下文变量聚焦在与当前预测相关的部分。

## 模型

对于时间步 $t'$ ，我们定义其上下文变量为：

$$
\textbf{c}_{t'} = \sum_{t=1}^T \alpha(\textbf{s}_{t' - 1}, \textbf{h}_t) \textbf{h}_t$$

也就是把时间步$t' - 1$ 的解码器隐状态 $\textbf{s}_{t' - 1}$ 作为查询，时间步 t 的编码器隐状态 $\textbf{h}_t$ 作为键和值，用加性注意力作为注意力权重 $\alpha$ ，来实时更新上下文 $\textbf{c}_{t'}$ 。这构成了 Bahdanau 注意力的架构。

![](/assets/RTSlbLuJiofJPxxcw1mcRGiRnpb.png)

## 定义注意力解码器

根据上面定义的模型，我们可以在之前的基础上对解码器进行修改，如下：

```py
class AttentionDecoder(d2l.Decoder):
    """带有注意力机制解码器的基本接口"""
    def __init__(self, **kwargs):
        super(AttentionDecoder, self).__init__(**kwargs)

    @property
    def attention_weights(self):
        raise NotImplementedError
        
class Seq2SeqAttentionDecoder(AttentionDecoder):
    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 dropout=0, **kwargs):
        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)
        self.attention = d2l.AdditiveAttention(
            num_hiddens, num_hiddens, num_hiddens, dropout)
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.rnn = nn.GRU(
            embed_size + num_hiddens, num_hiddens, num_layers,
            dropout=dropout)
        self.dense = nn.Linear(num_hiddens, vocab_size)

    def init_state(self, enc_outputs, enc_valid_lens, *args):
        # outputs的形状为(batch_size，num_steps，num_hiddens).
        # hidden_state的形状为(num_layers，batch_size，num_hiddens)
        outputs, hidden_state = enc_outputs
        return (outputs.permute(1, 0, 2), hidden_state, enc_valid_lens)

    def forward(self, X, state):
        # enc_outputs的形状为(batch_size,num_steps,num_hiddens).
        # hidden_state的形状为(num_layers,batch_size,
        # num_hiddens)
        enc_outputs, hidden_state, enc_valid_lens = state
        # 输出X的形状为(num_steps,batch_size,embed_size)
        X = self.embedding(X).permute(1, 0, 2)
        outputs, self._attention_weights = [], []
        for x in X:
            # query的形状为(batch_size,1,num_hiddens)
            query = torch.unsqueeze(hidden_state[-1], dim=1)
            # context的形状为(batch_size,1,num_hiddens)
            context = self.attention(
                query, enc_outputs, enc_outputs, enc_valid_lens)
            # 在特征维度上连结
            x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1)
            # 将x变形为(1,batch_size,embed_size+num_hiddens)
            out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)
            outputs.append(out)
            self._attention_weights.append(self.attention.attention_weights)
        # 全连接层变换后，outputs的形状为
        # (num_steps,batch_size,vocab_size)
        outputs = self.dense(torch.cat(outputs, dim=0))
        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state,
                                          enc_valid_lens]

    @property
    def attention_weights(self):
        return self._attention_weights
```

## 训练

训练的过程还是类似。由于加入了注意力机制，训练的速度会慢得多。

```py
embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1
batch_size, num_steps = 64, 10
lr, num_epochs, device = 0.005, 250, d2l.try_gpu()

train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)
encoder = d2l.Seq2SeqEncoder(
    len(src_vocab), embed_size, num_hiddens, num_layers, dropout)
decoder = Seq2SeqAttentionDecoder(
    len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)
net = d2l.EncoderDecoder(encoder, decoder)
d2l.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)
```

# 多头注意力

在图像的卷积神经网络中，我们通过多通道的卷积层和池化层来提取多个尺度上的图像信息。这样的思路在注意力系统中也可以参考。我们可能希望能有“多通道”的注意力汇聚，用来捕获各种范围的依赖关系（例如，短距离依赖和长距离依赖关系）。基于这种思路，我们可以设计多头注意力系统，即通过独立学习得到 $h$ 组不同的注意力汇聚，然后通过线性变换将这些不同的注意力头（每一个注意力汇聚称为一个头）变换为一个最终输出。

![](/assets/UnsJbYVRAoOFnJx6fvZcwBOunje.png)

## 模型

用数学语言描述上述过程，即对于查询 $\textbf{q} \in \mathbb{R}^{d_q}$ ， 键 $\textbf{k} \in \mathbb{R}^{d_q}$ 和值 $\textbf{v} \in \mathbb{R}^{d_v}$ ，每个注意力头的计算方法为：

$$
\textbf{h}_i = f(\textbf{W}_i^{(q)}\textbf{q}, \textbf{W}_i^{(k)}\textbf{k}, \textbf{W}_i^{(v)}\textbf{v},) \in \mathbb{R}^{p_v}$$

而对于 h 个注意力头，他们线性变换的过程为：

$$
\textbf{W}_o  \begin{bmatrix} \textbf{h}_1 \\ \vdots \\ \textbf{h}_h \end{bmatrix} \in \mathbb{R}^{p_o}$$

## 实现

在实现的时候，我们通常将“隐藏层”的单元数 $p_q$ ， $p_k$ ， $p_v$ 设为 $p_q = p_k = p_v = \frac{p_o}{h}$ ，这样做一方面可以避免计算代价和参数代价的大幅增长，另一方面也使得并行计算成为可能，加快了运算速度。

```py
def transpose_qkv(X, num_heads):
    """为了多注意力头的并行计算而变换形状"""
    # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)
    # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，
    # num_hiddens/num_heads)
    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)

    # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,
    # num_hiddens/num_heads)
    X = X.permute(0, 2, 1, 3)

    # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,
    # num_hiddens/num_heads)
    return X.reshape(-1, X.shape[2], X.shape[3])

def transpose_output(X, num_heads):
    """逆转transpose_qkv函数的操作"""
    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])
    X = X.permute(0, 2, 1, 3)
    return X.reshape(X.shape[0], X.shape[1], -1)

class MultiHeadAttention(nn.Module):
    """多头注意力"""
    def __init__(self, key_size, query_size, value_size, num_hiddens,
                 num_heads, dropout, bias=False, **kwargs):
        super(MultiHeadAttention, self).__init__(**kwargs)
        self.num_heads = num_heads
        self.attention = d2l.DotProductAttention(dropout)
        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)
        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)
        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)
        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)

    def forward(self, queries, keys, values, valid_lens):
        # queries，keys，values的形状:
        # (batch_size，查询或者“键－值”对的个数，num_hiddens)
        # valid_lens　的形状:
        # (batch_size，)或(batch_size，查询的个数)
        # 经过变换后，输出的queries，keys，values　的形状:
        # (batch_size*num_heads，查询或者“键－值”对的个数，
        # num_hiddens/num_heads)
        queries = transpose_qkv(self.W_q(queries), self.num_heads)
        keys = transpose_qkv(self.W_k(keys), self.num_heads)
        values = transpose_qkv(self.W_v(values), self.num_heads)

        if valid_lens is not None:
            # 在轴0，将第一项（标量或者矢量）复制num_heads次，
            # 然后如此复制第二项，然后诸如此类。
            valid_lens = torch.repeat_interleave(
                valid_lens, repeats=self.num_heads, dim=0)

        # output的形状:(batch_size*num_heads，查询的个数，
        # num_hiddens/num_heads)
        output = self.attention(queries, keys, values, valid_lens)

        # output_concat的形状:(batch_size，查询的个数，num_hiddens)
        output_concat = transpose_output(output, self.num_heads)
        return self.W_o(output_concat)
```

这里矩阵大小的变化较为复杂，通过下图可能会对理解有所帮助。

![](/assets/IX5mbF0kIo9M2Rx1RSocekvNnK8.png)

# 自注意力和位置编码

在第 4 节中，我们采用注意力机制进行文本的解码工作。类似地，这种机制也可以用在编码的过程中。由于这种情况下查询、键和值来自同一组输入，因此被称为自注意力。

## 自注意力

上述过程用数学语言表述即对于输入序列 $\{\textbf{x}_i\} \in \mathbb{R}^d$ ，其自注意力输出 $\{\textbf{y}_i\}$ 为：

$$
\textbf{y}_i = f(\textbf{x}_i, (\textbf{x}_1, \textbf{x}_1), \dots, (\textbf{x}_n, \textbf{x}_n)) \in \mathbb{R}^d$$

## 比较卷积神经网络、循环神经网络和自注意力

接下来比较下面几个架构，目标都是将由 $n$ 个词元组成的序列映射到另一个长度相等的序列，其中的每个输入词元或输出词元都由 $d$ 维向量表示。具体来说，将比较的是卷积神经网络、循环神经网络和自注意力这几个架构的计算复杂性、顺序操作和最大路径长度。请注意，顺序操作会妨碍并行计算，而任意的序列位置组合之间的路径越短，则能更轻松地学习序列中的远距离依赖关系。

![](/assets/JmLIbYHNFo3GFdxlWvEcCpmOnSd.png)

考虑一个卷积核大小为 $k$ 的卷积层。 在后面的章节将提供关于使用卷积神经网络处理序列的更多详细信息。 目前只需要知道的是，由于序列长度是 $n$ ，输入和输出的通道数量都是 $d$ ， 所以卷积层的计算复杂度为 $\mathcal{O}(knd^2)$ 。 如图所示， 卷积神经网络是分层的，因此为有 $\mathcal{O}(1)$ 个顺序操作， 最大路径长度为 $\mathcal{O}(\frac{n}{k})$ 。 例如， $\textbf{x}_1$ 和 $\textbf{x}_5$ 处于图中卷积核大小为 $3$ 的双层卷积神经网络的感受野内。

当更新循环神经网络的隐状态时，$d \times d$ 权重矩阵和 $d$ 维隐状态的乘法计算复杂度为 $\mathcal{O}(d^2)$ 。 由于序列长度为 $n$ ，因此循环神经网络层的计算复杂度为 $\mathcal{O}(nd^2)$ 。 根据图示， 有 $\mathcal{O}(n)$ 个顺序操作无法并行化，最大路径长度也是 $\mathcal{O}(n)$ 。

在自注意力中，查询、键和值都是 $n \times d$ 矩阵。 考虑第 3 节中缩放的”点－积“注意力， 其中 $n \times d$ 矩阵乘以 $d \times n$ 矩阵。 之后输出的 $n \times n$ 矩阵乘以 $n \times d$ 矩阵。 因此，自注意力具有 $\mathcal{O}(n^2d)$ 计算复杂性。 正如图中所讲， 每个词元都通过自注意力直接连接到任何其他词元。 因此，有 $\mathcal{O}(1)$ 个顺序操作可以并行计算， 最大路径长度也是 $\mathcal{O}(1)$ 。

总而言之，卷积神经网络和自注意力都拥有并行计算的优势， 而且自注意力的最大路径长度最短。 但是因为其计算复杂度是关于序列长度的二次方，所以在很长的序列中计算会非常慢。

## 位置编码

循环神经网络中处理词元序列时是按照顺序处理的，而自注意力因为并行计算所以不存在顺序操作关系。为了保留序列顺序信息，我们需要额外提供位置编码。这里我们介绍基于正余弦函数来计算的固定位置编码。

对于输入 $\textbf{X} \in \mathbb{R}^{n \times d}$ ，它表示一个序列中的 $n$ 个词元的 $d$ 维嵌入表示，则位置编码可以用一个形状相同的位置嵌入矩阵 $\textbf{P} \in \mathbb{R}^{n \times d}$ 表示，该矩阵的元素计算方式如下：

$$
\begin{align} p_{i, 2j} &= \sin{\frac{i}{10000^{\frac{2j}{d}}}} \\ p_{i, 2j + 1} &= \cos{\frac{i}{10000^{\frac{2j}{d}}}} \end{align}$$

 最后加上位置编码的结果为 $\textbf{X} + \textbf{P}$ 。

位置编码的实现如下：

```py
class PositionalEncoding(nn.Module):
    """位置编码"""
    def __init__(self, num_hiddens, dropout, max_len=1000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(dropout)
        # 创建一个足够长的P
        self.P = torch.zeros((1, max_len, num_hiddens))
        X = torch.arange(max_len, dtype=torch.float32).reshape(
            -1, 1) / torch.pow(10000, torch.arange(
            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)
        self.P[:, :, 0::2] = torch.sin(X)
        self.P[:, :, 1::2] = torch.cos(X)

    def forward(self, X):
        X = X + self.P[:, :X.shape[1], :].to(X.device)
        return self.dropout(X)
```

### 绝对位置信息

上述奇怪的位置编码信息其实与二进制表示非常类似。在二进制中，不同位置上的数字分别按照不同频率进行 0-1 交替。

```text
0: 000
1: 001
2: 010
3: 011
4: 100
5: 101
6: 110
7: 111
```

三角函数也是周期函数，也有一定的频率。这里我们位置编码中的不同位数放在三角函数内的分母就是起到不同位数表示不同频率的作用。只不过通过浮点数表示，可以比二进制表示更加节省空间。

### 相对位置信息

除了捕获绝对位置信息之外，上述的位置编码还允许模型学习得到输入序列中相对位置信息。 这是因为对于任何确定的位置偏移 $\delta$ ，位置 $i + \delta$ 处 的位置编码可以线性投影位置 $i$ 处的位置编码来表示。

这种投影的数学解释是，令 $\omega_j = \frac{1}{10000^{\frac{2j}{d}}}$ ， 对于任何确定的位置偏移 $d$ ，绝对位置编码中的任何一对 $(p_{i, 2j}, p_{i, 2j + 1})$ 都可以线性投影到 $(p_{i + \delta, 2j}, p_{i + \delta, 2j + 1})$ ：

$$
\begin{aligned} &\begin{bmatrix} \cos(\delta \omega_j) & \sin(\delta \omega_j) \\  -\sin(\delta \omega_j) & \cos(\delta \omega_j) \\ \end{bmatrix} \begin{bmatrix} p_{i, 2j} \\  p_{i, 2j+1} \\ \end{bmatrix}\\ =&\begin{bmatrix} \cos(\delta \omega_j) \sin(i \omega_j) + \sin(\delta \omega_j) \cos(i \omega_j) \\  -\sin(\delta \omega_j) \sin(i \omega_j) + \cos(\delta \omega_j) \cos(i \omega_j) \\ \end{bmatrix}\\ =&\begin{bmatrix} \sin\left((i+\delta) \omega_j\right) \\  \cos\left((i+\delta) \omega_j\right) \\ \end{bmatrix}\\ =& \begin{bmatrix} p_{i+\delta, 2j} \\  p_{i+\delta, 2j+1} \\ \end{bmatrix} \end{aligned}$$

# Transformer

通过第 6 节的比较，我们发现自注意力同时具有并行计算和最短的最大路径长度这两个优势。本节我们将介绍完全基于注意力机制，没有任何卷积层或循环神经网络层的 Transformer 模型。

## 模型

![](/assets/AgWfbwKLKouP0NxstuecQGuUnEd.png)

如图为 Transformer 模型的结构图。和之前的模型一样，这个模型也分为编码器和解码器两部分。编码器的部分有两个子层，第一层是多头自注意力层，接受来自源语言加上位置编码的序列信息；第二层是基于位置的前馈网络。模型中的每个子层都应用了残差连接，并在残差连接的加法后紧接着一层规范化层。

解码器的部分同样有多个层，且应用了残差连接和层规范化。除了编码器中描述的两个子层之外，解码器还在这两个子层之间插入了第三个子层，称为<em>编码器－解码器注意力</em>层。在编码器－解码器注意力中，查询来自前一个解码器层的输出，而键和值来自整个编码器的输出。在解码器自注意力中，查询、键和值都来自上一个解码器层的输出。但是，解码器中的每个位置只能考虑该位置之前的所有位置。这种<em>掩蔽</em>注意力保留了<em>自回归</em>属性，确保预测仅依赖于已生成的输出词元。

## 基于位置的前馈网络

基于位置的前馈网络指的是对于序列中的每一个位置都用同一个多层感知机，在同一个子层中每一个位置所用的参数是相同的，它们分别通过多层感知机得到输出张量。在下面的实现中，输入`X`的形状（批量大小，时间步数或序列长度，隐单元数或特征维度）将被一个两层的感知机转换成形状为（批量大小，时间步数，`ffn_num_outputs`）的输出张量。

```py
class PositionWiseFFN(nn.Module):
    """基于位置的前馈网络"""
    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,
                 **kwargs):
        super(PositionWiseFFN, self).__init__(**kwargs)
        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)
        self.relu = nn.ReLU()
        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)

    def forward(self, X):
        return self.dense2(self.relu(self.dense1(X)))
```

## 残差连接和层规范化

在之前的图像处理中我们用到了批量规范化，它和这里使用的层规范化很相似。但是由于在自然语言处理中，需要处理的对象通常是变长序列，所以用批量规范化的效果不如层规范化效果好。

这里在实现中我们也用到了暂退法实现正则化。

```py
class AddNorm(nn.Module):
    """残差连接后进行层规范化"""
    def __init__(self, normalized_shape, dropout, **kwargs):
        super(AddNorm, self).__init__(**kwargs)
        self.dropout = nn.Dropout(dropout)
        self.ln = nn.LayerNorm(normalized_shape)

    def forward(self, X, Y):
        return self.ln(self.dropout(Y) + X)
```

## 编码器

有了前馈网络层和残差连接与层规范化层，再加上之前实现的多头注意力层，我们就可以搭建一个基本的编码器层了。

```py
class EncoderBlock(nn.Module):
    """Transformer编码器块"""
    def __init__(self, key_size, query_size, value_size, num_hiddens,
                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,
                 dropout, use_bias=False, **kwargs):
        super(EncoderBlock, self).__init__(**kwargs)
        self.attention = d2l.MultiHeadAttention(
            key_size, query_size, value_size, num_hiddens, num_heads, dropout,
            use_bias)
        self.addnorm1 = AddNorm(norm_shape, dropout)
        self.ffn = PositionWiseFFN(
            ffn_num_input, ffn_num_hiddens, num_hiddens)
        self.addnorm2 = AddNorm(norm_shape, dropout)

    def forward(self, X, valid_lens):
        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))
        return self.addnorm2(Y, self.ffn(Y))
```

实现了一块之后，将这个块进行堆叠就能实现完整的编码器部分。由于这里使用的是值范围在 −1 和 1 之间的固定位置编码，因此通过学习得到的输入的嵌入表示的值需要先乘以嵌入维度的平方根进行重新缩放，然后再与位置编码相加。

```py
class TransformerEncoder(d2l.Encoder):
    """Transformer编码器"""
    def __init__(self, vocab_size, key_size, query_size, value_size,
                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,
                 num_heads, num_layers, dropout, use_bias=False, **kwargs):
        super(TransformerEncoder, self).__init__(**kwargs)
        self.num_hiddens = num_hiddens
        self.embedding = nn.Embedding(vocab_size, num_hiddens)
        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)
        self.blks = nn.Sequential()
        for i in range(num_layers):
            self.blks.add_module("block"+str(i),
                EncoderBlock(key_size, query_size, value_size, num_hiddens,
                             norm_shape, ffn_num_input, ffn_num_hiddens,
                             num_heads, dropout, use_bias))

    def forward(self, X, valid_lens, *args):
        # 因为位置编码值在-1和1之间，
        # 因此嵌入值乘以嵌入维度的平方根进行缩放，
        # 然后再与位置编码相加。
        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))
        self.attention_weights = [None] * len(self.blks)
        for i, blk in enumerate(self.blks):
            X = blk(X, valid_lens)
            self.attention_weights[
                i] = blk.attention.attention.attention_weights
        return X
```

## 解码器

解码器的实现与编码器类似，只是多了一层“编码器-解码器”注意力层，同时由于预测阶段输出词元是逐个生成的，所以需要通过指定长度来实现掩蔽后面的位置。

```py
class DecoderBlock(nn.Module):
    """解码器中第i个块"""
    def __init__(self, key_size, query_size, value_size, num_hiddens,
                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,
                 dropout, i, **kwargs):
        super(DecoderBlock, self).__init__(**kwargs)
        self.i = i
        self.attention1 = d2l.MultiHeadAttention(
            key_size, query_size, value_size, num_hiddens, num_heads, dropout)
        self.addnorm1 = AddNorm(norm_shape, dropout)
        self.attention2 = d2l.MultiHeadAttention(
            key_size, query_size, value_size, num_hiddens, num_heads, dropout)
        self.addnorm2 = AddNorm(norm_shape, dropout)
        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,
                                   num_hiddens)
        self.addnorm3 = AddNorm(norm_shape, dropout)

    def forward(self, X, state):
        enc_outputs, enc_valid_lens = state[0], state[1]
        # 训练阶段，输出序列的所有词元都在同一时间处理，
        # 因此state[2][self.i]初始化为None。
        # 预测阶段，输出序列是通过词元一个接着一个解码的，
        # 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示
        if state[2][self.i] is None:
            key_values = X
        else:
            key_values = torch.cat((state[2][self.i], X), axis=1)
        state[2][self.i] = key_values
        if self.training:
            batch_size, num_steps, _ = X.shape
            # dec_valid_lens的开头:(batch_size,num_steps),
            # 其中每一行是[1,2,...,num_steps]
            dec_valid_lens = torch.arange(
                1, num_steps + 1, device=X.device).repeat(batch_size, 1)
        else:
            dec_valid_lens = None

        # 自注意力
        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)
        Y = self.addnorm1(X, X2)
        # 编码器－解码器注意力。
        # enc_outputs的开头:(batch_size,num_steps,num_hiddens)
        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)
        Z = self.addnorm2(Y, Y2)
        return self.addnorm3(Z, self.ffn(Z)), state
```

同样进行堆叠可得到完整的解码器实现。最后，通过一个全连接层计算所有`vocab_size`个可能的输出词元的预测值。解码器的自注意力权重和编码器解码器注意力权重都被存储下来，方便日后可视化的需要。

```py
class TransformerDecoder(d2l.AttentionDecoder):
    def __init__(self, vocab_size, key_size, query_size, value_size,
                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,
                 num_heads, num_layers, dropout, **kwargs):
        super(TransformerDecoder, self).__init__(**kwargs)
        self.num_hiddens = num_hiddens
        self.num_layers = num_layers
        self.embedding = nn.Embedding(vocab_size, num_hiddens)
        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)
        self.blks = nn.Sequential()
        for i in range(num_layers):
            self.blks.add_module("block"+str(i),
                DecoderBlock(key_size, query_size, value_size, num_hiddens,
                             norm_shape, ffn_num_input, ffn_num_hiddens,
                             num_heads, dropout, i))
        self.dense = nn.Linear(num_hiddens, vocab_size)

    def init_state(self, enc_outputs, enc_valid_lens, *args):
        return [enc_outputs, enc_valid_lens, [None] * self.num_layers]

    def forward(self, X, state):
        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))
        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]
        for i, blk in enumerate(self.blks):
            X, state = blk(X, state)
            # 解码器自注意力权重
            self._attention_weights[0][
                i] = blk.attention1.attention.attention_weights
            # “编码器－解码器”自注意力权重
            self._attention_weights[1][
                i] = blk.attention2.attention.attention_weights
        return self.dense(X), state

    @property
    def attention_weights(self):
        return self._attention_weights
```

需要注意的是，由于第 9 章中 `predict_seq2seq` 的实现中，每次送入解码器的 `X` 都是批量大小为 1 ，时间步为 1 的，因此 `TransformerDecoder` 的 `forward` 函数第一步`X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))`将永远使用第一位置，导致在预测时解码器的位置编码失效。

根据评论区的讨论，可以在这一块做一些修改。大致思想是在预测时把之前每一步的预测结果拼接在一起保存在 `TransformerDecoder` 对象里，使得预测第 t 步目标时输入解码器的 X 是从第 0 步到第 t - 1 步的张量，而最后输出的结果只取与 t - 1 步对应的即可。

首先是 `DecoderBlock.forward` 删除了 `state[2]` 相关的代码，现在不需要使用使用 `state[2]` 维持状态：

```py
class DecoderBlock(nn.Module):
    """解码器中第i个块"""
    def __init__(self, key_size, query_size, value_size, num_hiddens,
                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,
                 dropout, i, **kwargs):
        super(DecoderBlock, self).__init__(**kwargs)
        self.i = i
        self.attention1 = d2l.MultiHeadAttention(
            key_size, query_size, value_size, num_hiddens, num_heads, dropout)
        self.addnorm1 = AddNorm(norm_shape, dropout)
        self.attention2 = d2l.MultiHeadAttention(
            key_size, query_size, value_size, num_hiddens, num_heads, dropout)
        self.addnorm2 = AddNorm(norm_shape, dropout)
        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,
                                   num_hiddens)
        self.addnorm3 = AddNorm(norm_shape, dropout)

    def forward(self, X, state):
        enc_outputs, enc_valid_lens = state[0], state[1]
        
        batch_size, num_steps, _ = X.shape
        # dec_valid_lens的开头:(batch_size,num_steps),
        # 其中每一行是[1,2,...,num_steps]
        dec_valid_lens = torch.arange(
            1, num_steps + 1, device=X.device).repeat(batch_size, 1)

        # 自注意力
        X2 = self.attention1(X, X, X, dec_valid_lens)
        Y = self.addnorm1(X, X2)
        # 编码器－解码器注意力。
        # enc_outputs的开头:(batch_size,num_steps,num_hiddens)
        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)
        Z = self.addnorm2(Y, Y2)
        return self.addnorm3(Z, self.ffn(Z)), state
```

之后是 `TransformerDecoder` ，`init_state` 中增加一个记录之前预测结果的属性，并且不需要有 `state[2]` 。 `forward` 中当不处于 `training` 状态时要保存每一步的预测结果，并且返回时只取最后一个时间步的结果：

```py
class TransformerDecoder(d2l.AttentionDecoder):
    def __init__(self, vocab_size, key_size, query_size, value_size,
                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,
                 num_heads, num_layers, dropout, **kwargs):
        super(TransformerDecoder, self).__init__(**kwargs)
        self.num_hiddens = num_hiddens
        self.num_layers = num_layers
        self.embedding = nn.Embedding(vocab_size, num_hiddens)
        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)
        self.blks = nn.Sequential()
        for i in range(num_layers):
            self.blks.add_module("block"+str(i),
                DecoderBlock(key_size, query_size, value_size, num_hiddens,
                             norm_shape, ffn_num_input, ffn_num_hiddens,
                             num_heads, dropout, i))
        self.dense = nn.Linear(num_hiddens, vocab_size)

    def init_state(self, enc_outputs, enc_valid_lens, *args):
        self.seqX = None
        return [enc_outputs, enc_valid_lens]

    def forward(self, X, state):
        if not self.training:
            self.seqX = X if self.seqX is None else torch.cat((self.seqX, X), dim=1)
            X = self.seqX

        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))
        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]
        for i, blk in enumerate(self.blks):
            X, state = blk(X, state)
            # 解码器自注意力权重
            self._attention_weights[0][
                i] = blk.attention1.attention.attention_weights
            # “编码器－解码器”自注意力权重
            self._attention_weights[1][
                i] = blk.attention2.attention.attention_weights
            
        if not self.training:
            return self.dense(X)[:, -1:, :], state
        
        return self.dense(X), state

    @property
    def attention_weights(self):
        return self._attention_weights
```

## 训练

训练部分还是类似，只需要指定一些超参数，再调用框架即可。

```py
num_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10
lr, num_epochs, device = 0.005, 200, d2l.try_gpu()
ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4
key_size, query_size, value_size = 32, 32, 32
norm_shape = [32]

train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)

encoder = TransformerEncoder(
    len(src_vocab), key_size, query_size, value_size, num_hiddens,
    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,
    num_layers, dropout)
decoder = TransformerDecoder(
    len(tgt_vocab), key_size, query_size, value_size, num_hiddens,
    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,
    num_layers, dropout)
net = d2l.EncoderDecoder(encoder, decoder)
d2l.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)
```

---

# 优化和深度学习

## 优化的目标

优化和深度学习的目标实际上存在着本质的不同。前者主要关注的是最小化目标，后者则关注在给定有限数据量的情况下寻找合适的模型。由于优化算法的目标函数通常是基于训练数据集的损失函数，因此优化的目标是减少训练误差。但是，深度学习（或更广义地说，统计推断）的目标是减少泛化误差。为了实现后者，除了使用优化算法来减少训练误差之外，我们还需要注意过拟合。

## 深度学习中的优化挑战

利用数值优化对深度学习目标函数进行优化的过程存在许多难题，本节将介绍其中最令人烦恼的三种：局部最小值、鞍点和梯度消失。

### 局部最小值

深度学习的目标函数 $f(x)$ 可能存在多个局部最小值（极小值），而一旦学习过程中目标函数接近某个局部最优解，由于梯度接近或变为零，可能会使迭代的结果陷入局部最优，于是最终迭代得到的结果将不会是全局最优。只有一定程度的噪声可能会使参数跳出局部最小值。事实上，这是小批量随机梯度下降的有利特性之一。在这种情况下，小批量上梯度的自然变化能够将参数从局部极小值中跳出。

### 鞍点

与极小值非常类似，鞍点也是一个常见的梯度消失的原因。鞍点是指函数的所有梯度都消失但既不是全局最小值也不是局部最小值的任何位置。例如 $f(x) = x^3$ 这个函数，在 $(0, 0)$ 位置它的导数为 $0$ ，但它不是极小值，更不是最小值。 

一个更经典而隐蔽的例子是函数 $F(x, y) = x^2 - y^2$ 。它的鞍点为 $(0,0)$ 。这是关于 $x$ 的最大值，也是关于 $y$ 的最小值。此外，它看起来像个马鞍，这就是鞍点的名字由来。

我们假设函数的输入是 $k$ 维向量，其输出是标量，因此其 Hessian 矩阵（也称黑塞矩阵）将有 $k$ 个特征值。函数的解可能是局部最小值、局部最大值或函数梯度为零位置处的鞍点：

- 当函数在零梯度位置处的 Hessian 矩阵的特征值全部为正值时，我们有该函数的局部最小值；
- 当函数在零梯度位置处的 Hessian 矩阵的特征值全部为负值时，我们有该函数的局部最大值；
- 当函数在零梯度位置处的 Hessian 矩阵的特征值为负值和正值时，我们有该函数的一个鞍点。

对于高维度问题，至少<em>部分</em>特征值为负的可能性相当高。这使得鞍点比局部最小值更有可能出现。我们将在下一节介绍凸性时讨论这种情况的一些例外。简而言之，凸函数是 Hessian 函数的特征值永远不为负值的函数。不幸的是，大多数深度学习问题并不属于这一类。尽管如此，它还是研究优化算法的一个很好的工具。

### 梯度消失

梯度消失可能是最隐蔽的问题之一。它通常和激活函数的选择有关。例如 sigmoid 函数和 tanh 函数，它们在自变量超出一定范围以后导数会趋于零，这种情况下基于梯度的优化会停滞不前。事实证明，这是在引入ReLU激活函数之前训练深度学习模型相当棘手的原因之一。

# 凸性

## 凸集

凸集的定义：如果对于任意 $a, b \in \mathcal{X}$ ，连接 $a$ 和 $b$ 的线段也位于 $\mathcal{X}$ 中，则向量空间中的一个集合 $\mathcal{X}$ 是凸的。也就是对于凸集 $\mathcal{X}$ 存在以下关系：

$$
\forall \lambda \in [0, 1], \lambda a + (1 - \lambda) b \in \mathcal{X} \ \text{当 } a, b \in \mathcal{X}$$

容易证得：凸集的交集是凸集，即给定凸集 $\mathcal{X}_i$ ，有 $\cap_{i} \mathcal{X}_i$ 也是凸集。下图可以形象地说明。

与之相反，凸集的并集不一定是并集，下图为一个简单的反例。

通常，深度学习中的问题是在凸集上定义的。例如， $\mathbb{R}^d$ ，即实数的 $d$ -维向量的集合是凸集（毕竟 $\mathbb{R}^d$ 中任意两点之间的线存在于 $\mathbb{R}^d$ 中）。 在某些情况下，我们使用有界长度的变量，例如球的半径定义为 $\{\mathbf{x} | \mathbf{x} \in \mathbb{R}^d \text{ 且 } \| \mathbf{x} \| \leq r\}$ 。

## 凸函数

有了凸集的定义后我们可以定义凸函数。给定一个凸集 $\mathcal{X}$ ，如果对于所有 $x, x' \in \mathcal{X}$ 和所有 $\lambda \in [0, 1]$ 在函数 $f : \mathcal{X} \to \mathbb{R}$ 有

$$
\lambda f(x) + (1 - \lambda) f(x') \geq f(\lambda x + (1 - \lambda) x')$$

 则函数 $f$ 是凸函数。

## 琴生不等式

琴生不等式是凸性定义的一种推广。该不等式如下：

$$
\sum_i \alpha_i f(x_i) \geq f(\sum_i \alpha_i x_i)$$

其中 $\alpha_i$ 是满足 $\sum_i \alpha_i = 1$ 的非负实数。用一个更简单直观的形式来表达，就是：

$$
E_X[f(X)] \geq f(E_X[X])$$

即凸函数的期望不小于期望的凸函数。

琴生不等式的一个常见应用：用一个较简单的表达式约束一个较复杂的表达式。 例如，它可以应用于部分观察到的随机变量的对数似然。 具体地说，由于 $\int P(Y)P(X \mid Y) dY = P(X)$ ，所以

$$
E_{Y \sim P(Y)} [-\log{P(X \mid Y)}] \geq -\log{P(X)}$$

这里， $Y$ 是典型的未观察到的随机变量， $P(Y)$ 是它可能如何分布的最佳猜测， $P(X)$ 是将 $Y$ 积分后的分布。例如，在聚类中 $Y$ 可能是簇标签，而在应用簇标签时， $P(X \mid Y)$ 是生成模型。

## 性质

### 局部最小值是全局最小值

对一个凸函数，其局部最小值就是全局最小值。下面用反证法证明。

假设 $x^* \in \mathcal{X}$ 是一个局部最小值，则存在一个很小的正值 $\delta$ ，使得当 $x \in \mathcal{X}$ 满足 $0 < |x - x^*| < \delta$ 时，有 $f(x) < f(x^*)$ 。

现在假设局部最小值 $x^*$ 不是函数 $f$ 的全局最小值，即存在 $x' \in \mathcal{X}$ 使得 $f(x') < f(x^*)$ 。令 $\lambda = 1 - \frac{p}{|x^* - x'|}$ ，则有

$$
0 < |\lambda x^* + (1 - \lambda) x' - x^*| \leq p$$

而由于 $\lambda \in [0, 1)$ ，故由凸函数的性质，有

$$
\begin{align} f(\lambda x^* + (1 - \lambda)x') &\leq \lambda f(x^*) + (1 - \lambda)f(x') \\ &\leq \lambda f(x^*) + (1 - \lambda)f(x^*) \\ &= f(x^*) \end{align}$$

这与 $x^*$ 是局部最小值矛盾。因此，不存在 $x' \in \mathcal{X}$ 满足 $f(x') < f(x^*)$ 。综上所述，局部最小值 $x^*$ 就是全局最小值。

### 凸函数的下水平集是凸的

给定一个定义在凸集 $\mathcal{X}$ 上的凸函数 $f$ ，其任意一个下水平集：

$$
\mathcal{S}_b := \{x \mid x \in \mathcal{X} \text{ and } f(x) \leq b\}$$

是凸的。

我们快速证明一下。对 $\exist x, x' \in \mathcal{S}_b, \lambda \in [0, 1]$ ，有

$$
f(\lambda x + (1 - \lambda)x') \leq \lambda f(x) + (1 - \lambda)f(x') \leq b$$

故 $\lambda x + (1 - \lambda)x' \in \mathcal{S}_b$ ，则 $\mathcal{S}_b$ 为凸集。

### 凸性和二阶导数

如果函数的二阶导数 $f: \mathbb{R}^n \to \mathbb{R}$ 存在，则该函数是凸函数当且仅当它的黑塞矩阵 $\nabla^2 f \succeq 0$ 。

首先证明一维的情况。先证明凸函数的 $f''(x) \geq 0 。取 \epsilon \to 0$ ，有

$$
\frac12 f(x + \epsilon) + \frac12 f(x - \epsilon) \geq f(\frac{x + \epsilon}{2} + \frac{x - \epsilon}{2}) = f(x)$$

由导数的定义，可得

$$
f''(x) = \lim_{\epsilon \to 0}{\frac{f(x + \epsilon) + f(x - \epsilon) -2f(x)}{\epsilon^2}} \geq 0$$

接着证明由 $f''(x) \geq 0$ 可推得 $f$ 为凸函数。由于 $f''(x) \geq 0$ ，故 $f'(x)$ 为单调非递减函数。假设 $a < x < b$ 为 $\mathbb{R}$ 中的三个点，其中， $x = (1 - \lambda)a + \lambda b, \lambda \in (0, 1)$ 。根据中值定理，存在 $\alpha \in [a, x], \beta \in [x, b]$ ，使得

$$
\begin{align} f'(\alpha) &= \frac{f(x) - f(a)}{x - a} \\ f'(\beta) &= \frac{f(b) - f(x)}{b - x} \end{align}$$

由 $f'(x)$ 单调性可知 $f'(\beta) \geq f'(\alpha)$ ，因此

$$
\begin{align} \frac{f(b) - f(x)}{b - x} &\geq \frac{f(x) - f(a)}{x - a} \\ \frac{f(b)}{b - x} + \frac{f(a)}{x - a} &\geq \frac{f(x)}{x - a} + \frac{f(x)}{b - x} \\ (x - a)f(b) + (b - x)f(a) &\geq [(b - x) + (x - a)]f(x) \\ \frac{x - a}{b - a}f(b) + \frac{b - x}{b - a}f(a) &\geq f(x) \end{align}$$

由于 $x = (1 - \lambda)a + \lambda b$ ，所以

$$
\lambda f(b) +(1 - \lambda)f(a) \geq f((1 - \lambda)f(a) + \lambda f(b))$$

故凸性得证。

第二，我们需要一个引理证明多维情况：$f: \mathbb{R}^n \to \mathbb{R}$ 是凸的当且仅当对于所有 $\textbf{x}, \textbf{y} \in \mathbb{R}^n$ ，有

$$
g(z) \stackrel{\mathrm{def}}{=} f(z \textbf{x} + (1 - z) \textbf{y}) \text{ where } z \in [0, 1]$$

是凸的。

先证明由 $f$ 为凸函数可推得 $g$ 为凸函数。$\forall a, b, \lambda \in [0, 1]$ ，有

$$
\begin{align} &g(\lambda a + (1 - \lambda) b) \\ =&f((\lambda a + (1 - \lambda)b)\textbf{x} + (1 - \lambda a - (1 - \lambda) b)\textbf{y}) \\ =&f(\lambda(a \textbf{x} + (1 - a)\textbf{y}) + (1 - \lambda)(b \textbf{x} + (1 - b) \textbf{y})) \\ \leq &\lambda f(a \textbf{x} + (1 - a)\textbf{y}) + (1 - \lambda)f(b \textbf{x} + (1 - b)\textbf{y}) \\ =&\lambda g(a) + (1 - \lambda)g(b) \end{align}$$

得证。

接下来证 $g$ 为凸函数可推得 $f$ 为凸函数。$\forall \lambda \in [0, 1]$ ，有

$$
\begin{align} &f(\lambda \textbf{x} + (1 - \lambda)\textbf{y}) \\ =&g(\lambda \cdot 1 + (1 - \lambda) \cdot 0) \\ \leq & \lambda g(1) + (1 - \lambda)g(0) \\ =&\lambda f(x) + (1 - \lambda)f(\textbf{y}) \end{align}$$

得证。

最后，利用上面的引理和一维情况的结果，我们可以证明多维情况： 多维函数 $f: \mathbb{R}^n \to \mathbb{R}$ 是凸函数当且仅当 $g(z) \stackrel{\mathrm{def}}{=} f(z \textbf{x} + (1 - z) \textbf{y})$ 是凸函数，其中 $z \in [0, 1] ， \textbf{x}, \textbf{y} \in \mathbb{R}^n$ 。根据一维情况， 此条成立的条件为，当且仅当对于所有 $\textbf{x}, \textbf{y} \in \mathbb{R}^n$ ，有 $g'' = (\textbf{x} - \textbf{y})^T \textbf{H} (\textbf{x} - \textbf{y}) \geq 0 (\textbf{H} \stackrel{\mathrm{def}}{=} \nabla^2 f)$ 。这相当于根据半正定矩阵的定义， $\textbf{H} \succeq 0$ 。

## 约束

凸优化的一个很好的特性是能够让我们有效地处理约束。 即它使我们能够解决以下形式的约束优化问题：

$$
\mathop{\mathrm{minimize}}_\textbf{x} f(\textbf{x}) \text{ subject to } c_i(\textbf{x}) \leq 0 \text{ for all } i \in \{1, \ldots, N\}$$

这里 $f$ 是目标函数， $c_i$ 是约束函数。 例如第一个约束 $c_1(\textbf{x}) = ||\textbf{x}||_2 -$$ ，则参数 $\textbf{x}$ 被限制为单位球。 如果第二个约束 $c_2(\textbf{x}) = \textbf{v}^T \textbf{x} + b$ ，那么这对应于半空间上所有的 $\textbf{x}$ 。 同时满足这两个约束等于选择一个球的切片作为约束集。

### 拉格朗日函数

对函数 $f(x)$ 的优化可以转化为求如下拉格朗日函数的鞍点：

$$
L(\textbf{x}, \alpha_1, \ldots, \alpha_n) = f(\textbf{x}) + \sum_{i = 1}^n \alpha_i c_i(\textbf{x}) \text{ where } \alpha_i \geq 0$$

### 惩罚

拉格朗日函数法是将约束添加到目标函数来确保不会严重违反约束。事实上，例如多层感知机中的权重衰减也是类似的想法，通过在目标函数中加入 $\frac{\lambda}{2} |\textbf{w}|^2$ ，可以确保 $\textbf{w}$ 不会增长太大。 使用约束优化的观点，我们可以看到，对于若干半径 $r$ ，这将确保 $|\textbf{w}|^2 - r^2 \leq 0$ 。 通过调整 $\lambda$ 的值，我们可以改变 $\textbf{w}$ 的大小。

通常，添加惩罚是确保近似满足约束的一种好方法。 在实践中，这被证明比精确的满意度更可靠。 此外，对于非凸问题，许多使精确方法在凸情况下的性质（例如，可求最优解）不再成立。

### 投影

满足约束条件的另一种策略是投影。这一点在之前的梯度截断中也用到过：

$$
\textbf{g} \leftarrow \textbf{g} \cdot \min{(1, \frac{\theta}{||\textbf{g}||})}$$

以确保梯度上限以 $\theta$ 为界限。这就是 $\textbf{g}$ 在半径为 $\theta$ 的球上的投影。更泛化地说，在凸集 $\mathcal{X}$ 上的投影被定义为

$$
\mathrm{Proj}_\mathcal{X}(\mathbf{x}) = \mathop{\mathrm{argmin}}_{\mathbf{x}' \in \mathcal{X}} \|\mathbf{x} - \mathbf{x}'\|.$$

它是 $\mathcal{X}$ 中离 $\textbf{x}$ 最近的点。为了更清晰直观地展示，我们用两幅图来举例。

图中有两个凸集，一个圆和一个菱形。 两个集合内的点（黄色）在投影期间保持不变。 两个集合（黑色）之外的点投影到集合中接近原始点（黑色）的点（红色）。

# 梯度下降

## 一维梯度下降

一维梯度函数可以直观地展示梯度下降的过程。考虑一类连续可微实值函数 $f: \mathbb{R} \to \mathbb{R}$ ，利用泰勒展开，可得

$$
f(x + \epsilon) = f(x) + \epsilon f'(x) + \mathcal{O}(\epsilon^2)$$

我们假设在负梯度方向上移动的 $\epsilon$ 会减少 $f$ 。令步长 $\eta > 0$ ，然后取 $\epsilon = -\eta f'(x)$ ，将其带入泰勒展开式可得

$$
f(x - \eta f'(x)) = f(x) - \eta f'^2(x) + \mathcal{O}(\eta^2 f'^2(x))$$

而我们总可以令 $\eta$ 小到足以使高阶项变得不相关，故有

$$
f(x - \eta f'(x)) \lessapprox f(x)$$

即如果我们用

$$
x \leftarrow x - \eta f'(x)$$

来迭代更新 $x$ ，函数 $f(x)$ 的值可能会下降。

下图为对 $f(x) = x^2$ 利用梯度下降寻找极小值的图示。

### 学习率

在梯度下降的过程中，超参数学习率的设定对迭代的影响非常关键。如果使用的学习率太小，将导致 $x$ 的更新非常缓慢，需要更多的迭代。 而如果使用过大的学习率，则梯度下降的过程可能会跳过极小值点而陷入我们不想见到的情况，例如下图中的发散。

### 局部最小值

如果函数存在多个极小值，则在梯度下降迭代的过程中将会陷入其中某一个局部最小值。最终得到哪一个极小值可能取决于学习率的设置。

## 多元梯度下降

现在我们考虑自变量为多元的情况，即 $\textbf{x} = [x_1, x_2, \ldots, x_d]^T$ ，此时目标函数 $f: \mathbb{R}^d \to \mathbb{R}$ 将向量映射为标量。相应地，它的梯度也是多元的，它是一个由 d 个偏导数组成的向量：

$$\nabla f(\textbf{x}) = [\frac{\partial f(\textbf{x})}{\partial x_1}, \frac{\partial f(\textbf{x})}{\partial x_2}, \ldots, \frac{\partial f(\textbf{x})}{\partial x_d}]^T$$

此时同样可以应用泰勒展开：

$$
f(\textbf{x} + \boldsymbol{\epsilon}) = f(\textbf{x}) + \boldsymbol{\epsilon}^T \nabla f(\textbf{x}) + \mathcal{O}(||\boldsymbol{\epsilon}||^2)$$

于是我们用下式进行更新：

$$
\textbf{x} \leftarrow \textbf{x} - \eta \nabla f(\textbf{x})$$

## 自适应方法

从上面的介绍中可以看到，学习率 $\eta$ 的选择对梯度下降的结果影响很大，如何选择恰当的值是一个很棘手的问题。能不能自动确定 $\eta$ ，或者完全不必选择学习率，会怎么样？下面是一些想法，虽然它们的计算代价使得它们不能直接应用于深度学习，但是这些思想为高级优化算法提供了思路。

### 牛顿法

对函数 $f: \mathbb{R}^d \to \mathbb{R}$ 进行二阶泰勒展开，可得：

$$
f(\textbf{x} + \boldsymbol{\epsilon}) = f(\textbf{x}) + \boldsymbol{\epsilon}^T \nabla f(\textbf{x}) + \frac12 \boldsymbol{\epsilon}^T \nabla^2 f(\textbf{x}) \boldsymbol{\epsilon} + \mathcal{O}{(||\boldsymbol{\epsilon}||^3)}$$

我们用 $\mathbf{H} \stackrel{\mathrm{def}}{=} \nabla^2 f(\mathbf{x})$ 表示 f 的黑塞矩阵， 它是一个 $d \times d$ 的矩阵。我们将泰勒展开式对 $\boldsymbol{\epsilon}$ 求导，可得

$$
\nabla f(\textbf{x}) + \textbf{H} \boldsymbol{\epsilon} = 0 \text{ and hence } \boldsymbol{\epsilon} = -\textbf{H}^{-1} \nabla f(\textbf{x})$$

即我们可以用下式进行迭代更新：

$$
\textbf{x} \leftarrow \textbf{x} - \textbf{H}^{-1} \nabla f(\textbf{x})$$

如图为对 $f(x) = cosh(x)$ 进行牛顿法优化的图示：

需要注意的是，由于在计算中加入了二阶导，此时如果二阶导为负数，则可能会使迭代方向为梯度下降方向的反向，即使函数值增大的方向，如图：

为了解决这个问题，一种想法是取黑塞矩阵的绝对值来修正，另一种方法是重新引入学习率。这似乎违背了初衷，但不完全是——拥有二阶信息可以使我们在曲率较大时保持谨慎，而在目标函数较平坦时则采用较大的学习率。下图是在 $\eta = 0.5$ 的情况下的迭代示意图，如我们所见，我们有了一个相当高效的算法。

### 收敛性分析

现在我们以一维凸函数 $f$ 为例分析牛顿法收敛速度。由于多变量情况下的证明是对以下一维参数情况证明的直接拓展，对我们理解这个问题不能提供更多帮助，因此我们省略了多变量情况的证明。

用 $x^{(k)}$ 表示 $x$ 在第 $k$ 次迭代时的值，令 $e^{(k)} \stackrel{\mathrm{def}}{=} x^{(k)} - x^*$ 表示第 $k$ 次迭代时与极小值的距离。由泰勒展开， $f'(x^*) = 0$ 可以写成：

$$
0 = f'(x^{(k)} - e^{(k)}) = f'(x^{(k)}) - e^{(k)} f''(x^{(k)}) + \frac12 (e^{(k)})^2 f'''(\xi^{(k)})$$

对某些 $\xi^{(k)} \in [x^{(k)} - e^{(k)}, x^{(k)}]$ 成立。将上述展开式除以 $f''(x^{(k)})$ 得

$$
e^{(k)} - \frac{f'(x^{(k)})}{f''(x^{(k)})} = \frac{1}{2} (e^{(k)})^2 \frac{f'''(\xi^{(k)})}{f''(x^{(k)})}.$$

将迭代更新关系式 $x^{(k + 1)} = x^{(k)} - \frac{f'(x^{(k)})}{f''(x^{(k)})}$ 代入，取绝对值，得

$$
|e^{(k + 1)}| = \frac12 (e^{(k)})^2 \frac{|f'''(\xi^{(k)})|}{f''(x^{(k)})}$$

因此，每当我们处于有界区域 $\frac{|f'''(\xi^{(k)})|}{2f''(x^{(k)})} \leq c$ ，我们有一个二次递减误差：

$$
|e^{(k + 1)}| \leq c (e^{(k)})^2$$

另一方面，优化研究人员称之为“线性”收敛，而将 $|e^{(k + 1)}| \leq \alpha |e^{(k)}|$ 这样的条件称为“恒定”收敛速度。

### 预处理

计算和存储完整的 Hessian 非常昂贵，而改善这个问题的一种方法是“预处理”。 它回避了计算整个 Hessian ，而只计算“对角线”项，即如下的算法更新：

$$
\textbf{x} \leftarrow \textbf{x} - \eta \mathrm{diag}{(\textbf{H})^{-1}} \nabla f(\textbf{x})$$

虽然这不如完整的牛顿法精确，但它仍然比不使用要好得多。

### 梯度下降和线搜索

梯度下降的一个关键问题是我们可能会超过目标或进展不足， 解决这一问题的简单方法是结合使用线搜索和梯度下降。 也就是说，我们使用 $\nabla f(\textbf{x})$ 给出的方向， 然后进行二分搜索，以确定哪个学习率 $\eta$ 使 $f(\textbf{x} - \eta \nabla f(\textbf{x}))$ 取最小值。

有关分析和证明，此算法收敛迅速。 然而，对深度学习而言，这不太可行。 因为线搜索的每一步都需要评估整个数据集上的目标函数，实现它的方式太昂贵了。

# 随机梯度下降

## 随机梯度更新

在深度学习中，目标函数通常是训练数据集中每个样本的损失函数的平均值。给定 $n$ 个样本的训练数据集，我们假设 $f_i(\textbf{x})$ 是关于索引 $i$ 的训练样本的损失函数，其中 $\textbf{x}$ 是参数向量。然后我们得到目标函数

$$
f(\textbf{x}) = \frac1n \sum_{i = 1}^n f_i(\textbf{x})$$

$\textbf{x}$ 的目标函数的梯度计算为

$$
\nabla f(\textbf{x}) = \frac1n \sum_{i = 1}^n \nabla f_i(\textbf{x})$$

计算时间复杂度为 $\mathcal{O}(n)$ ，代价过大，因此采用随机梯度下降的方法，即在每次迭代中，对数据样本随机均匀采样一个索引 $i$ ，其中 $i \in \{1, \ldots, n\}$ ，并计算梯度 $\nabla f_i(\textbf{x})$ 以更新 $\textbf{x}$ ：

$$
\textbf{x} \leftarrow \textbf{x} - \eta \nabla f_i(\textbf{x})$$

这样单次迭代的复杂度就降到了 $\mathcal{O}(1)$ 。需要强调的是，随机梯度 $\nabla f_i(\textbf{x})$ 是对完整梯度 $\nabla f(\textbf{x})$ 的无偏估计，因为

$$
\mathbb{E}_i \nabla f_i(\mathbf{x}) = \frac{1}{n} \sum_{i = 1}^n \nabla f_i(\mathbf{x}) = \nabla f(\mathbf{x})$$

这意味着，平均而言，随机梯度是对梯度的良好估计。

尽管理论上随机梯度表现应良好，但实际应用中相比完整的梯度下降，迭代过程还是会嘈杂得多，质量不会那么好。想要解决这个问题就需要在优化过程中动态降低学习率。

## 动态学习率

以下是随着时间推移调整 \eta 时使用的一些基本策略：

$$
\begin{aligned} \eta(t) & = \eta_i \text{ if } t_i \leq t \leq t_{i+1}  && \text{分段常数} \\ \eta(t) & = \eta_0 \cdot e^{-\lambda t} && \text{指数衰减} \\ \eta(t) & = \eta_0 \cdot (\beta t + 1)^{-\alpha} && \text{多项式衰减} \end{aligned}$$

第一种分段常数的方法，通常在每次优化进度停顿时降低学习率；第二种方法往往会使算法收敛之前过早停止；第三种方法最受欢迎的选择是 $\alpha = 0.5$ ，这种方法在凸优化背景下表现良好。

关于如何设置学习率，还有更多的选择。例如，我们可以从较小的学习率开始，然后使其迅速上涨，再让它降低，尽管这会更慢。我们甚至可以在较小和较大的学习率之间切换。

# 小批量随机梯度下降

第三节中使用完整数据集进行梯度更新复杂度太大，效率不高；第四节中每次只使用一个随机的训练样本，无法充分利用向量化，效率浪费较大。这暗示了两者之间可能有折中方案，这便涉及到小批量随机梯度下降。

## 向量化和缓存

计算一个矩阵乘法 $\textbf{A} = \textbf{BC}$ 由很多种方法，如：

1. 通过点积逐元素计算，即 $\textbf{A}_{ij} = \textbf{B}_{i, :} \textbf{C}_{:, j}^T$
2. 一次计算一行 / 一列，如 $\textbf{A}_{:, j} = \textbf{B} \textbf{C}_{:, j}^T$
3. 直接计算 $\textbf{A} = \textbf{BC}$
4. 分块计算

第四种选择提供了一个实践上很有用的方案：我们可以将矩阵的区块移到缓存中然后在本地将它们相乘。

## 小批量

处理单个观测值需要我们执行许多单一矩阵-矢量（甚至矢量-矢量）乘法，这耗费相当大，而且对应深度学习框架也要巨大的开销。这既适用于计算梯度以更新参数时，也适用于用神经网络预测。 也就是说，每当我们执行 $\textbf{w} \leftarrow \textbf{w} - \eta_t \textbf{g}_t$ 时，消耗巨大。其中

$$
\textbf{g}_t = \partial_\textbf{w} f(\textbf{x}_t, \textbf{w})$$

我们可以通过将其应用于一个小批量观测值来提高此操作的<em>计算</em>效率。 也就是说，我们将梯度 $\textbf{g}_t$ 替换为一个小批量而不是单个观测值

$$
\textbf{g}_t = \partial_\textbf{w} \frac{1}{|\mathcal{B}_t|} \sum_{i \in \mathcal{B}_t} f(\textbf{x}_t, \textbf{w})$$

让我们看看这对 $\textbf{g}_t$ 的统计属性有什么影响：由于 $\textbf{x}_t$ 和小批量 $\mathcal{B}_t$ 的所有元素都是从训练集中随机抽出的，因此梯度的期望保持不变。 另一方面，方差显著降低。 由于小批量梯度由正在被平均计算的 $b := |\mathcal{B}_t|$ 个独立梯度组成，其标准差降低了 $b^{-\frac12}$ 。 这本身就是一件好事，因为这意味着更新与完整的梯度更接近了。

## 读取数据集

数据集在读取后应用了批量规范化，减去了批量的均值并将方差缩放到 1 。

```py
d2l.DATA_HUB['airfoil'] = (d2l.DATA_URL + 'airfoil_self_noise.dat',
                           '76e5be1548fd8222e5074cf0faae75edff8cf93f')

def get_data_ch11(batch_size=10, n=1500):
    data = np.genfromtxt(d2l.download('airfoil'),
                         dtype=np.float32, delimiter='\t')
    data = torch.from_numpy((data - data.mean(axis=0)) / data.std(axis=0))
    data_iter = d2l.load_array((data[:n, :-1], data[:n, -1]),
                               batch_size, is_train=True)
    return data_iter, data.shape[1]-1
```

## 从零开始实现

之前已经实现过小批量随机梯度下降算法，这里将它的输入参数变得更加通用，主要是为了方便后面介绍的其他优化算法也可以使用同样的输入。 具体来说，我们添加了一个状态输入 `states` 并将超参数放在字典 `hyperparams` 中。 此外，我们将在训练函数里对各个小批量样本的损失求平均，因此优化算法中的梯度不需要除以批量大小。

```py
def sgd(params, states, hyperparams):
    for p in params:
        p.data.sub_(hyperparams['lr'] * p.grad)
        p.grad.data.zero_()
```

下面实现一个通用的训练函数，以方便后面介绍的其他优化算法使用。 它初始化了一个线性回归模型，然后可以使用小批量随机梯度下降以及后续小节介绍的其他算法来训练模型。

```py
def train_ch11(trainer_fn, states, hyperparams, data_iter,
               feature_dim, num_epochs=2):
    # 初始化模型
    w = torch.normal(mean=0.0, std=0.01, size=(feature_dim, 1),
                     requires_grad=True)
    b = torch.zeros((1), requires_grad=True)
    net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss
    # 训练模型
    animator = d2l.Animator(xlabel='epoch', ylabel='loss',
                            xlim=[0, num_epochs], ylim=[0.22, 0.35])
    n, timer = 0, d2l.Timer()
    for _ in range(num_epochs):
        for X, y in data_iter:
            l = loss(net(X), y).mean()
            l.backward()
            trainer_fn([w, b], states, hyperparams)
            n += X.shape[0]
            if n % 200 == 0:
                timer.stop()
                animator.add(n/X.shape[0]/len(data_iter),
                             (d2l.evaluate_loss(net, data_iter, loss),))
                timer.start()
    print(f'loss: {animator.Y[0][-1]:.3f}, {timer.avg():.3f} sec/epoch')
    return timer.cumsum(), animator.Y[0]
```

## 简洁实现

下面用深度学习框架自带算法实现一个通用的训练函数，我们将在后续的其它小节使用它。

```py
def train_concise_ch11(trainer_fn, hyperparams, data_iter, num_epochs=4):
    # 初始化模型
    net = nn.Sequential(nn.Linear(5, 1))
    def init_weights(m):
        if type(m) == nn.Linear:
            torch.nn.init.normal_(m.weight, std=0.01)
    net.apply(init_weights)

    optimizer = trainer_fn(net.parameters(), **hyperparams)
    loss = nn.MSELoss(reduction='none')
    animator = d2l.Animator(xlabel='epoch', ylabel='loss',
                            xlim=[0, num_epochs], ylim=[0.22, 0.35])
    n, timer = 0, d2l.Timer()
    for _ in range(num_epochs):
        for X, y in data_iter:
            optimizer.zero_grad()
            out = net(X)
            y = y.reshape(out.shape)
            l = loss(out, y)
            l.mean().backward()
            optimizer.step()
            n += X.shape[0]
            if n % 200 == 0:
                timer.stop()
                # MSELoss计算平方误差时不带系数1/2
                animator.add(n/X.shape[0]/len(data_iter),
                             (d2l.evaluate_loss(net, data_iter, loss) / 2,))
                timer.start()
    print(f'loss: {animator.Y[0][-1]:.3f}, {timer.avg():.3f} sec/epoch')
```

# 动量法

## 基础

### 泄露平均值

小批量随机梯度下降可以通过以下方式计算：

$$
\mathbf{g}_{t, t-1} = \partial_{\mathbf{w}} \frac{1}{|\mathcal{B}_t|} \sum_{i \in \mathcal{B}_t} f(\mathbf{x}_{i}, \mathbf{w}_{t-1}) = \frac{1}{|\mathcal{B}_t|} \sum_{i \in \mathcal{B}_t} \mathbf{h}_{i, t-1}$$

为了保持记法简单，在这里我们使用 $\mathbf{h}_{i, t-1} = \partial_{\mathbf{w}} f(\mathbf{x}_i, \mathbf{w}_{t-1})$ 作为样本 $i$ 的随机梯度下降，使用时间 $t - 1$ 时更新的权重 $t - 1$ 。 如果我们能够从方差减少的影响中受益，甚至超过小批量上的梯度平均值，那很不错。 完成这项任务的一种选择是用<em>泄漏平均值</em>取代梯度计算：

$$
\mathbf{v}_t = \beta \mathbf{v}_{t-1} + \mathbf{g}_{t, t-1}$$

其中 $\beta \in (0, 1)$ 。 这有效地将瞬时梯度替换为多个“过去”梯度的平均值。 $\textbf{v}$ 被称为<em>动量</em>， 它累加了过去的梯度。 为了更详细地解释，让我们递归地将 $\textbf{v}_t$ 扩展到

$$
\mathbf{v}_t = \beta^2 \mathbf{v}_{t-2} + \beta \mathbf{g}_{t-1, t-2} + \mathbf{g}_{t, t-1} = \ldots, = \sum_{\tau = 0}^{t-1} \beta^{\tau} \mathbf{g}_{t-\tau, t-\tau-1}$$

其中，较大的 $\beta$ 相当于长期平均值，而较小的 $\beta$ 相对于梯度法只是略有修正。 新的梯度替换不再指向特定实例下降最陡的方向，而是指向过去梯度的加权平均值的方向。 这使我们能够实现对单批量计算平均值的大部分好处，而不产生实际计算其梯度的代价。

### 有效样本权重

回想一下 $\mathbf{v}_t = \sum_{\tau = 0}^{t-1} \beta^{\tau} \mathbf{g}_{t-\tau, t-\tau-1}$ 。 极限条件下， $\sum_{\tau=0}^\infty \beta^\tau = \frac{1}{1-\beta}$ 。 换句话说，不同于在梯度下降或者随机梯度下降中取步长 $\eta$ ，我们选取步长 $\frac{\eta}{1 - \beta}$ ，同时处理潜在表现可能会更好的下降方向。

## 实际实验

### 从零开始实现

相比于小批量随机梯度下降，动量方法需要维护一组辅助变量，即速度。 它与梯度以及优化问题的变量具有相同的形状。 在下面的实现中，我们称这些变量为`states`。

```py
def init_momentum_states(feature_dim):
    v_w = torch.zeros((feature_dim, 1))
    v_b = torch.zeros(1)
    return (v_w, v_b)

def sgd_momentum(params, states, hyperparams):
    for p, v in zip(params, states):
        with torch.no_grad():
            v[:] = hyperparams['momentum'] * v + p.grad
            p[:] -= hyperparams['lr'] * v
        p.grad.data.zero_()
```

### 简洁实现

```py
trainer = torch.optim.SGD
d2l.train_concise_ch11(trainer, {'lr': 0.005, 'momentum': 0.9}, data_iter)
```

## 理论分析

### 二次凸函数

考虑这个函数

$$
h(\mathbf{x}) = \frac{1}{2} \mathbf{x}^\top \mathbf{Q} \mathbf{x} + \mathbf{x}^\top \mathbf{c} + b$$

这是一个普通的二次函数。 对于正定矩阵 $\mathbf{Q} \succ 0$ ，即对于具有正特征值的矩阵，有最小化器为 $\mathbf{x}^* = -\mathbf{Q}^{-1} \mathbf{c}$ ，最小值为 $b - \frac{1}{2} \mathbf{c}^\top \mathbf{Q}^{-1} \mathbf{c}$ 。 因此我们可以将 $ℎ$ 重写为

$$
h(\mathbf{x}) = \frac{1}{2} (\mathbf{x} - \mathbf{Q}^{-1} \mathbf{c})^\top \mathbf{Q} (\mathbf{x} - \mathbf{Q}^{-1} \mathbf{c}) + b - \frac{1}{2} \mathbf{c}^\top \mathbf{Q}^{-1} \mathbf{c}$$

梯度由 $\partial_{\mathbf{x}} f(\mathbf{x}) = \mathbf{Q} (\mathbf{x} - \mathbf{Q}^{-1} \mathbf{c})$ 给出。 也就是说，它是由 $\textbf{x}$ 和最小化器之间的距离乘以 $\textbf{Q}$ 所得出的。 因此，动量法还是 $\mathbf{Q} (\mathbf{x}_t - \mathbf{Q}^{-1} \mathbf{c})$ 的线性组合。

由于 Q 是正定的，因此可以通过 $\mathbf{Q} = \mathbf{O}^\top \boldsymbol{\Lambda} \mathbf{O}$ 分解为正交（旋转）矩阵 $O$ 和正特征值的对角矩阵 $\boldsymbol{\Lambda}$ 。 这使我们能够将变量从 $\textbf{x}$ 更改为 $\mathbf{z} := \mathbf{O} (\mathbf{x} - \mathbf{Q}^{-1} \mathbf{c})$ ，以获得一个非常简化的表达式：

$$
h(\mathbf{z}) = \frac{1}{2} \mathbf{z}^\top \boldsymbol{\Lambda} \mathbf{z} + b'$$

这里 $b' = b - \frac{1}{2} \mathbf{c}^\top \mathbf{Q}^{-1} \mathbf{c}$ 。 由于 $\textbf{O}$ 只是一个正交矩阵，因此不会真正意义上扰动梯度。 以 $\textbf{z}$ 表示的梯度下降变成

$$
\mathbf{z}_t = \mathbf{z}_{t-1} - \boldsymbol{\Lambda} \mathbf{z}_{t-1} = (\mathbf{I} - \boldsymbol{\Lambda}) \mathbf{z}_{t-1}$$

这个表达式中的重要事实是梯度下降在不同的特征空间之间不会混合。 也就是说，如果用 $\textbf{Q}$ 的特征系统来表示，优化问题是以逐坐标顺序的方式进行的。 这在动量法中也适用。

$$
\begin{split}\begin{aligned} \mathbf{v}_t & = \beta \mathbf{v}_{t-1} + \boldsymbol{\Lambda} \mathbf{z}_{t-1} \\ \mathbf{z}_t & = \mathbf{z}_{t-1} - \eta \left(\beta \mathbf{v}_{t-1} + \boldsymbol{\Lambda} \mathbf{z}_{t-1}\right) \\     & = (\mathbf{I} - \eta \boldsymbol{\Lambda}) \mathbf{z}_{t-1} - \eta \beta \mathbf{v}_{t-1} \end{aligned}\end{split}$$

在这样做的过程中，我们只是证明了以下定理：带有和带有不凸二次函数动量的梯度下降，可以分解为朝二次矩阵特征向量方向坐标顺序的优化。

### 标量函数

鉴于上述结果，让我们看看当我们最小化函数 $f(x) = \frac{\lambda}{2} x^2$ 时会发生什么。 对于梯度下降我们有

$$
x_{t+1} = x_t - \eta \lambda x_t = (1 - \eta \lambda) x_t$$

每 $|1 - \eta \lambda| < 1$ 时，这种优化以指数速度收敛，因为在 $t$ 步之后我们可以得到 $x_t = (1 - \eta \lambda)^t x_0$ 。 这显示了在我们将学习率 $\eta$ 提高到 $\eta \lambda = 1$ 之前，收敛率最初是如何提高的。 超过该数值之后，梯度开始发散，对于 $\eta \lambda > 2$ 而言，优化问题将会发散。

为了分析动量的收敛情况，我们首先用两个标量重写更新方程：一个用于 $x$ ，另一个用于动量 $v$ 。这产生了：

$$
\begin{split}\begin{bmatrix} v_{t+1} \\ x_{t+1} \end{bmatrix} = \begin{bmatrix} \beta & \lambda \\ -\eta \beta & (1 - \eta \lambda) \end{bmatrix} \begin{bmatrix} v_{t} \\ x_{t} \end{bmatrix} = \mathbf{R}(\beta, \eta, \lambda) \begin{bmatrix} v_{t} \\ x_{t} \end{bmatrix}\end{split}$$

我们用 $\textbf{R}$ 来表示 $2 \times 2$ 管理的收敛表现。 在 $t$ 步之后，最初的值 $[v_0, x_0]$ 变为 $\mathbf{R}(\beta, \eta, \lambda)^t [v_0, x_0]$ 。 因此，收敛速度是由 $\textbf{R}$ 的特征值决定的。 简而言之，当 $0 < \eta \lambda < 2 + 2 \beta$ 时动量收敛。 与梯度下降的 $0 < \eta \lambda < 2$ 相比，这是更大范围的可行参数。 另外，一般而言较大值的 $\beta$ 是可取的。

# AdaGrad 算法

## 稀疏特征和学习率

在训练语言模型中，经常会出现稀疏特征（即只在偶尔出现的特征）。只有在这些不常见的特征出现时，与其相关的参数才会得到有意义的更新。 鉴于学习率下降，我们可能最终会面临这样的情况：常见特征的参数相当迅速地收敛到最佳值，而对于不常见的特征，我们仍缺乏足够的观测以确定其最佳值。 换句话说，学习率要么对于常见特征而言降低太慢，要么对于不常见特征而言降低太快。

解决此问题的一个方法是记录我们看到特定特征的次数，然后将其用作调整学习率。 即我们可以使用大小为$\eta_i = \frac{\eta_0}{\sqrt{s(i, t) + c}}$ 的学习率，而不是 $\eta = \frac{\eta_0}{\sqrt{t + c}}$ 。 在这里 $s(i, t)$ 计下了我们截至 $t$ 时观察到功能 $i$ 的次数。 这其实很容易实施且不产生额外损耗。

AdaGrad 算法通过将粗略的计数器 $s(i, t)$ 替换为先前观察所得梯度的平方之和来解决这个问题。 它使用 $s(i, t+1) = s(i, t) + \left(\partial_i f(\mathbf{x})\right)^2$ 来调整学习率。 这有两个好处：首先，我们不再需要决定梯度何时算足够大。 其次，它会随梯度的大小自动变化。通常对应于较大梯度的坐标会显著缩小，而其他梯度较小的坐标则会得到更平滑的处理。 在实际应用中，它促成了计算广告学及其相关问题中非常有效的优化程序。 但是，它遮盖了 AdaGrad 固有的一些额外优势，这些优势在预处理环境中很容易被理解。

## 预处理

正如在第 6 节中那样，我们可以根据其特征分解 $\mathbf{Q} = \mathbf{U}^\top \boldsymbol{\Lambda} \mathbf{U}$ 重写 $f(\mathbf{x}) = \frac{1}{2} \mathbf{x}^\top \mathbf{Q} \mathbf{x} + \mathbf{c}^\top \mathbf{x} + b$ 这个问题，来得到一个简化得多的问题，使每个坐标都可以单独解出：

$$
f(\mathbf{x}) = \bar{f}(\bar{\mathbf{x}}) = \frac{1}{2} \bar{\mathbf{x}}^\top \boldsymbol{\Lambda} \bar{\mathbf{x}} + \bar{\mathbf{c}}^\top \bar{\mathbf{x}} + b$$

在这里我们使用了 $\mathbf{x} = \mathbf{U} \mathbf{x}$ ，且因此 $\mathbf{c} = \mathbf{U} \mathbf{c}$ 。 修改后优化器为 $\bar{\mathbf{x}} = -\boldsymbol{\Lambda}^{-1} \bar{\mathbf{c}}$ 且最小值为 $-\frac{1}{2} \bar{\mathbf{c}}^\top \boldsymbol{\Lambda}^{-1} \bar{\mathbf{c}} + b$ 。 这样更容易计算，因为 $\boldsymbol{\Lambda}$ 是一个包含 $\mathbf{Q}$ 特征值的对角矩阵。

如果稍微扰动 $\mathbf{c}$ ，我们会期望在 $f$ 的最小化器中只产生微小的变化。遗憾的是，情况并非如此。虽然 $\mathbf{c}$ 的微小变化导致了 $\bar{\mathbf{c}}$ 同样的微小变化，但 $f$ 的（以及 $\bar{f}$ 的）最小化器并非如此。每当特征值 $\boldsymbol{\Lambda}_i$ 很大时，我们只会看到 $\bar{x}_i$ 和 $\bar{f}$ 的最小值发生微小变化。相反，对小的 $\boldsymbol{\Lambda}_i$ 来说， $\bar{x}_i$ 的变化可能是剧烈的。最大和最小的特征值之比称为优化问题的条件数。

$$
\kappa = \frac{\boldsymbol{\Lambda}_1}{\boldsymbol{\Lambda}_d}$$

如果条件编号 $\kappa$ 很大，准确解决优化问题就会很难。我们需要确保在获取大量动态的特征值范围时足够谨慎：难道我们不能简单地通过扭曲空间来“修复”这个问题，从而使所有特征值都是1？理论上这很容易：我们只需要 $\mathbf{Q}$ 的特征值和特征向量即可将问题从 $\mathbf{x}$ 整理到 $\mathbf{z} := \boldsymbol{\Lambda}^{\frac{1}{2}} \mathbf{U} \mathbf{x}$ 中的一个。在新的坐标系中， $\mathbf{x}^\top \mathbf{Q} \mathbf{x}$ 可以被简化为 $\|\mathbf{z}\|^2$ 。可惜，这是一个相当不切实际的想法。一般而言，计算特征值和特征向量要比解决实际问题“贵”得多。

虽然准确计算特征值可能会很昂贵，但即便只是大致猜测并计算它们，也可能已经比不做任何事情好得多。特别是，我们可以使用 \mathbf{Q} 的对角线条目并相应地重新缩放它。这比计算特征值开销小的多。

$$
\tilde{\mathbf{Q}} = \mathrm{diag}^{-\frac{1}{2}}(\mathbf{Q}) \mathbf{Q} \mathrm{diag}^{-\frac{1}{2}}(\mathbf{Q})$$

在这种情况下，我们得到了 $\tilde{\mathbf{Q}}_{ij} = \frac{\mathbf{Q}_{ij}}{\sqrt{\mathbf{Q}_{ii} \mathbf{Q}_{jj}}}$ ，特别注意对于所有 $i$ ， $\tilde{\mathbf{Q}}_{ii} = 1$ 。 在大多数情况下，这大大简化了条件数。 例如我们之前讨论的案例，它将完全消除眼下的问题，因为问题是轴对齐的。

遗憾的是，我们还面临另一个问题：在深度学习中，我们通常情况甚至无法计算目标函数的二阶导数：对于 $\textbf{x} \in \mathbb{R}^d$ ，即使只在小批量上，二阶导数可能也需要 $\mathcal{O}{(d^2)}$ 空间来计算，导致几乎不可行。 AdaGrad 算法巧妙的思路是，使用一个代理来表示黑塞矩阵的对角线，既相对易于计算又高效。

为了了解它是如何生效的，让我们来看看 $\bar{f}(\bar{\mathbf{x}})$ 。 我们有

$$
\partial_{\bar{\mathbf{x}}} \bar{f}(\bar{\mathbf{x}}) = \boldsymbol{\Lambda} \bar{\mathbf{x}} + \bar{\mathbf{c}} = \boldsymbol{\Lambda} \left(\bar{\mathbf{x}} - \bar{\mathbf{x}}_0\right)$$

其中 $\bar{\mathbf{x}}_0$ 是 $\bar{f}$ 的优化器。 因此，梯度的大小取决于 $\boldsymbol{\Lambda}$ 和与最佳值的差值。 如果 $\bar{\mathbf{x}} - \bar{\mathbf{x}}_0$ 没有改变，那这就是我们所求的。 毕竟在这种情况下，梯度 $\partial_{\bar{\mathbf{x}}} \bar{f}(\bar{\mathbf{x}})$ 的大小就足够了。 由于 AdaGrad 算法是一种随机梯度下降算法，所以即使是在最佳值中，我们也会看到具有非零方差的梯度。 因此，我们可以放心地使用梯度的方差作为黑塞矩阵比例的廉价替代。

## 算法

我们使用变量 $\textbf{s}_t$ 来累加过去的梯度方差，如下所示：

$$
\begin{split}\begin{aligned}     \mathbf{g}_t & = \partial_{\mathbf{w}} l(y_t, f(\mathbf{x}_t, \mathbf{w})) \\     \mathbf{s}_t & = \mathbf{s}_{t-1} + \mathbf{g}_t^2 \\     \mathbf{w}_t & = \mathbf{w}_{t-1} - \frac{\eta}{\sqrt{\mathbf{s}_t + \epsilon}} \cdot \mathbf{g}_t \end{aligned}\end{split}$$

在这里，操作是按照坐标顺序应用。与之前一样， $\eta$ 是学习率， $\epsilon$ 是一个为维持数值稳定性而添加的常数，用来确保我们不会除以 $0$ 。 最后，我们初始化 $\mathbf{s}_0 = \mathbf{0}$ 。

就像在动量法中我们需要跟踪一个辅助变量一样，在 AdaGrad 算法中，我们允许每个坐标有单独的学习率。 与 SGD 算法相比，这并没有明显增加 AdaGrad 的计算代价，因为主要计算用在 $l(y_t, f(\mathbf{x}_t, \mathbf{w}))$ 及其导数。

请注意，在 $\mathbf{s}_t$ 中累加平方梯度意味着 $\mathbf{s}_t$ 基本上以线性速率增长（由于梯度从最初开始衰减，实际上比线性慢一些）。 这产生了一个学习率 $\mathcal{O}(t^{-\frac{1}{2}})$ ，但是在单个坐标的层面上进行了调整。 对于凸问题，这完全足够了。

## 从零开始实现

同动量法一样， AdaGrad 算法需要对每个自变量维护同它一样形状的状态变量。

```py
def init_adagrad_states(feature_dim):
    s_w = torch.zeros((feature_dim, 1))
    s_b = torch.zeros(1)
    return (s_w, s_b)

def adagrad(params, states, hyperparams):
    eps = 1e-6
    for p, s in zip(params, states):
        with torch.no_grad():
            s[:] += torch.square(p.grad)
            p[:] -= hyperparams['lr'] * p.grad / torch.sqrt(s + eps)
        p.grad.data.zero_()
```

## 简洁实现

```py
trainer = torch.optim.Adagrad
d2l.train_concise_ch11(trainer, {'lr': 0.1}, data_iter)
```

# RMSProp 算法

注意到 AdaGrad 算法的关键问题之一，是学习率按预定时间表 $\mathcal{O}(t^{-\frac12})$ 显著降低。虽然这通常适用于凸问题，但对于深度学习中遇到的非凸问题，可能并不理想。 但是，作为一个预处理器， Adagrad 算法按坐标顺序的适应性是非常可取的。

于是我们以 RMSProp 算法作为将速率调度与坐标自适应学习率分离的简单修复方法。之前的问题在于， Adagrad 算法将梯度 $\mathbf{g}_t$ 的平方累加成状态矢量 $\mathbf{s}_t = \mathbf{s}_{t-1} + \mathbf{g}_t^2$ 。 因此，由于缺乏规范化，没有约束力， $\mathbf{s}_t$ 持续增长，几乎上是在算法收敛时呈线性递增。

解决此问题的一种方法是使用 $\frac{\mathbf{s}_t }{t}$ 。 对 $\mathbf{g}_t$ 的合理分布来说，它将收敛。 遗憾的是，限制行为生效可能需要很长时间，因为该流程记住了值的完整轨迹。 另一种方法是按动量法中的方式使用泄漏平均值，即 $\mathbf{s}_t \leftarrow \gamma \mathbf{s}_{t-1} + (1-\gamma) \mathbf{g}_t^2$ ，其中参数 $\gamma > 0$ 。 保持所有其它部分不变就产生了 RMSProp 算法。

## 算法

用详细的方程式表示就是：

$$
\begin{split}\begin{aligned}     \mathbf{s}_t & \leftarrow \gamma \mathbf{s}_{t-1} + (1 - \gamma) \mathbf{g}_t^2 \\     \mathbf{x}_t & \leftarrow \mathbf{x}_{t-1} - \frac{\eta}{\sqrt{\mathbf{s}_t + \epsilon}} \odot \mathbf{g}_t \end{aligned}\end{split}$$

常数 $\epsilon > 0$ 通常设置为 $10^{−6}$，以确保我们不会因除以零或步长过大而受到影响。 鉴于这种扩展，我们现在可以自由控制学习率 $\eta$ ，而不考虑基于每个坐标应用的缩放。 就泄漏平均值而言，我们可以采用与之前在动量法中适用的相同推理。 扩展 $\mathbf{s}_t$ 定义可获得

$$
\begin{split}\begin{aligned} \mathbf{s}_t & = (1 - \gamma) \mathbf{g}_t^2 + \gamma \mathbf{s}_{t-1} \\ & = (1 - \gamma) \left(\mathbf{g}_t^2 + \gamma \mathbf{g}_{t-1}^2 + \gamma^2 \mathbf{g}_{t-2} + \ldots, \right) \end{aligned}\end{split}$$

和第 6 节一样，我们使用 $1 + \gamma + \gamma^2 + \ldots, = \frac{1}{1-\gamma}$ 。 因此，权重总和标准化为 1 且观测值的半衰期为 $\gamma^{-1}$ 。

## 从零开始实现

```py
def init_rmsprop_states(feature_dim):
    s_w = torch.zeros((feature_dim, 1))
    s_b = torch.zeros(1)
    return (s_w, s_b)

def rmsprop(params, states, hyperparams):
    gamma, eps = hyperparams['gamma'], 1e-6
    for p, s in zip(params, states):
        with torch.no_grad():
            s[:] = gamma * s + (1 - gamma) * torch.square(p.grad)
            p[:] -= hyperparams['lr'] * p.grad / torch.sqrt(s + eps)
        p.grad.data.zero_()
```

## 简洁实现

```py
trainer = torch.optim.RMSprop
d2l.train_concise_ch11(trainer, {'lr': 0.01, 'alpha': 0.9},
                       data_iter)
```

# AdaDelta

AdaDelta 是 AdaGrad 的另一变体，主要区别在于前者减少了学习率适应坐标的数量。 此外，广义上 Adadelta 被认为没有学习率，因为它使用变化量本身作为未来变化的校准。

## AdaDelta 算法

简而言之，Adadelta使用两个状态变量， $\mathbf{s}_t$ 用于存储梯度二阶导数的泄露平均值， $\Delta\mathbf{x}_t$ 用于存储模型本身中参数变化二阶导数的泄露平均值。

在 AdaDelta 中，我们的泄露更新如下：

$$
\mathbf{s}_t = \rho \mathbf{s}_{t-1} + (1 - \rho) \mathbf{g}_t^2$$

与 RMSProp 的区别在于，我们使用重新缩放的梯度 $\mathbf{g}_t'$ 执行更新，即

$$
\mathbf{x}_t  = \mathbf{x}_{t-1} - \mathbf{g}_t'$$

调整后的 $\mathbf{g}_t'$ 计算方式如下：

$$
\mathbf{g}_t' = \frac{\sqrt{\Delta\mathbf{x}_{t-1} + \epsilon}}{\sqrt{{\mathbf{s}_t + \epsilon}}} \odot \mathbf{g}_t$$

其中 $\Delta \mathbf{x}_{t-1}$ 是重新缩放梯度的平方 $\mathbf{g}_t'$ 的泄漏平均值。我们将 $\Delta \mathbf{x}_{0}$ 初始化为 0 ，然后在每个步骤中使用 $\mathbf{g}_t'$ 更新它，即

$$
\Delta \mathbf{x}_t = \rho \Delta\mathbf{x}_{t-1} + (1 - \rho) {\mathbf{g}_t'}^2$$

$\epsilon$ （例如 $10^{−5}$ 这样的小值）是为了保持数字稳定性而加入的。

## 从零开始实现

```py
def init_adadelta_states(feature_dim):
    s_w, s_b = torch.zeros((feature_dim, 1)), torch.zeros(1)
    delta_w, delta_b = torch.zeros((feature_dim, 1)), torch.zeros(1)
    return ((s_w, delta_w), (s_b, delta_b))

def adadelta(params, states, hyperparams):
    rho, eps = hyperparams['rho'], 1e-5
    for p, (s, delta) in zip(params, states):
        with torch.no_grad():
            # In-placeupdatesvia[:]
            s[:] = rho * s + (1 - rho) * torch.square(p.grad)
            g = (torch.sqrt(delta + eps) / torch.sqrt(s + eps)) * p.grad
            p[:] -= g
            delta[:] = rho * delta + (1 - rho) * g * g
        p.grad.data.zero_()
```

## 简洁实现

```py
trainer = torch.optim.Adadelta
d2l.train_concise_ch11(trainer, {'rho': 0.9}, data_iter)
```

# Adam 算法

Adam 算法是将前几节的技术汇总到一个高效的学习算法。这里，我们先简要回顾以下这些技术：

- 随机梯度下降在解决优化问题时比梯度下降更有效
- 在一个小批量中使用更大的观测值集，可以通过向量化提供额外效率。这是高效的多机、多 GPU 和整体并行处理的关键
- 向量机制用于汇总过去梯度的历史以加速收敛
- AdaGrade 通过对每个坐标缩放来实现高效计算的预处理器
- RMSProp 通过学习率的调整来分离每个坐标的缩放

## 算法

Adam 算法的关键组成部分之一是：它使用指数加权移动平均值来估算梯度的动量和二次矩，即它使用状态变量

$$
\begin{split}\begin{aligned}     \mathbf{v}_t & \leftarrow \beta_1 \mathbf{v}_{t-1} + (1 - \beta_1) \mathbf{g}_t \\     \mathbf{s}_t & \leftarrow \beta_2 \mathbf{s}_{t-1} + (1 - \beta_2) \mathbf{g}_t^2 \end{aligned}\end{split}$$

这里 $\beta_1$ 和 $\beta_2$ 是非负加权参数。 常将它们设置为 $\beta_1 = 0.9$ 和 $\beta_2 = 0.999$ 。 也就是说，方差估计的移动远远慢于动量估计的移动。 注意，如果我们初始化 $\mathbf{v}_0 = \mathbf{s}_0 = 0$ ，就会获得一个相当大的初始偏差。 我们可以通过使用 $\sum_{i=0}^t \beta^i = \frac{1 - \beta^t}{1 - \beta}$ 来解决这个问题。 相应地，标准化状态变量由下式获得

$$
\hat{\mathbf{v}}_t = \frac{\mathbf{v}_t}{1 - \beta_1^t} \text{ and } \hat{\mathbf{s}}_t = \frac{\mathbf{s}_t}{1 - \beta_2^t}$$

有了正确的估计，我们现在可以写出更新方程。 首先，我们以非常类似于 RMSProp 算法的方式重新缩放梯度以获得

$$
\mathbf{g}_t' = \frac{\eta \hat{\mathbf{v}}_t}{\sqrt{\hat{\mathbf{s}}_t} + \epsilon}$$

与 RMSProp 不同，我们的更新使用动量 $\hat{\mathbf{v}}_t$ 而不是梯度本身。 此外，由于使用 $\frac{1}{\sqrt{\hat{\mathbf{s}}_t} + \epsilon}$ 而不是 $\frac{1}{\sqrt{\hat{\mathbf{s}}_t + \epsilon}}$ 进行缩放，两者会略有差异。 前者在实践中效果略好一些，因此与 RMSProp 算法有所区分。 通常，我们选择 $\epsilon = 10^{-6}$ ，这是为了在数值稳定性和逼真度之间取得良好的平衡。

最后，我们简单更新：

$$
\mathbf{x}_t \leftarrow \mathbf{x}_{t-1} - \mathbf{g}_t'$$

## 实现

```py
def init_adam_states(feature_dim):
    v_w, v_b = torch.zeros((feature_dim, 1)), torch.zeros(1)
    s_w, s_b = torch.zeros((feature_dim, 1)), torch.zeros(1)
    return ((v_w, s_w), (v_b, s_b))

def adam(params, states, hyperparams):
    beta1, beta2, eps = 0.9, 0.999, 1e-6
    for p, (v, s) in zip(params, states):
        with torch.no_grad():
            v[:] = beta1 * v + (1 - beta1) * p.grad
            s[:] = beta2 * s + (1 - beta2) * torch.square(p.grad)
            v_bias_corr = v / (1 - beta1 ** hyperparams['t'])
            s_bias_corr = s / (1 - beta2 ** hyperparams['t'])
            p[:] -= hyperparams['lr'] * v_bias_corr / (torch.sqrt(s_bias_corr)
                                                       + eps)
        p.grad.data.zero_()
    hyperparams['t'] += 1
```

## Yogi

Adam 算法也存在一些问题： 即使在凸环境下，当 $\mathbf{s}_t$ 的二次矩估计值爆炸时，它可能无法收敛。一种改进方法是重写 Adam 算法更新如下：

$$
\mathbf{s}_t \leftarrow \mathbf{s}_{t-1} + (1 - \beta_2) \left(\mathbf{g}_t^2 - \mathbf{s}_{t-1}\right)$$

每当 $\mathbf{g}_t^2$ 具有值很大的变量或更新很稀疏时， $\mathbf{s}_t$ 可能会太快地“忘记”过去的值。 一个有效的解决方法是将 $\mathbf{g}_t^2 - \mathbf{s}_{t-1}$ 替换为 $\mathbf{g}_t^2 \odot \mathop{\mathrm{sgn}}(\mathbf{g}_t^2 - \mathbf{s}_{t-1})$ 。 这就是 Yogi 更新，现在更新的规模不再取决于偏差的量。

$$
\mathbf{s}_t \leftarrow \mathbf{s}_{t-1} + (1 - \beta_2) \mathbf{g}_t^2 \odot \mathop{\mathrm{sgn}}(\mathbf{g}_t^2 - \mathbf{s}_{t-1})$$

方法的提出者还进一步建议用更大的初始批量来初始化动量，而不仅仅是初始的逐点估计。

```py
def yogi(params, states, hyperparams):
    beta1, beta2, eps = 0.9, 0.999, 1e-3
    for p, (v, s) in zip(params, states):
        with torch.no_grad():
            v[:] = beta1 * v + (1 - beta1) * p.grad
            s[:] = s + (1 - beta2) * torch.sign(
                torch.square(p.grad) - s) * torch.square(p.grad)
            v_bias_corr = v / (1 - beta1 ** hyperparams['t'])
            s_bias_corr = s / (1 - beta2 ** hyperparams['t'])
            p[:] -= hyperparams['lr'] * v_bias_corr / (torch.sqrt(s_bias_corr)
                                                       + eps)
        p.grad.data.zero_()
    hyperparams['t'] += 1

data_iter, feature_dim = d2l.get_data_ch11(batch_size=10)
d2l.train_ch11(yogi, init_adam_states(feature_dim),
               {'lr': 0.01, 't': 1}, data_iter, feature_dim)
```

# 学习率调度器

调整学习率在优化中是非常重要的一部分，有如下几方面需要考虑：

- 首先，学习率的大小很重要。如果它太大，优化就会发散；如果它太小，训练就会需要过长时间，或者我们最终只能得到次优的结果。我们之前看到问题的条件数很重要。直观地说，这是最不敏感与最敏感方向的变化量的比率。
- 其次，衰减速率同样很重要。如果学习率持续过高，我们可能最终会在最小值附近弹跳，从而无法达到最优解。第 5 节比较详细地讨论了这一点，在第 4 节中我们则分析了性能保证。简而言之，我们希望速率衰减，但要比 $\mathcal{O}(t^{-\frac12})$ 慢，这样能成为解决凸问题的不错选择。
- 另一个同样重要的方面是初始化。这既涉及参数最初的设置方式，又关系到它们最初的演变方式。这被戏称为预热，即我们最初开始向着解决方案迈进的速度有多快。一开始的大步可能没有好处，特别是因为最初的参数集是随机的。最初的更新方向可能也是毫无意义的。
- 最后，还有许多优化变体可以执行周期性学习率调整。

## 单因子调度器

多项式衰减的一种替代方案是乘法衰减，即 $\eta_{t+1} \leftarrow \eta_t \cdot \alpha$ 其中 $\alpha \in (0, 1)$ 。 为了防止学习率衰减到一个合理的下界之下， 更新方程经常修改为 $\eta_{t+1} \leftarrow \mathop{\mathrm{max}}(\eta_{\mathrm{min}}, \eta_t \cdot \alpha)$ 。

```py
class FactorScheduler:
    def __init__(self, factor=1, stop_factor_lr=1e-7, base_lr=0.1):
        self.factor = factor
        self.stop_factor_lr = stop_factor_lr
        self.base_lr = base_lr

    def __call__(self, num_update):
        self.base_lr = max(self.stop_factor_lr, self.base_lr * self.factor)
        return self.base_lr
```

## 多因子调度器

训练深度网络的常见策略之一是保持学习率为一组分段的常量，并且不时地按给定的参数对学习率做乘法衰减。 具体地说，给定一组降低学习率的时间点，例如 $s = \{5, 10, 20\}$ ， 每当 $t \in s$ 时，降低 $\eta_{t+1} \leftarrow \eta_t \cdot \alpha$ 。 假设每步中的值减半，我们可以按如下方式实现这一点。

```py
net = net_fn()
trainer = torch.optim.SGD(net.parameters(), lr=0.5)
scheduler = lr_scheduler.MultiStepLR(trainer, milestones=[15, 30], gamma=0.5)

def get_lr(trainer, scheduler):
    lr = scheduler.get_last_lr()[0]
    trainer.step()
    scheduler.step()
    return lr
```

这种分段恒定学习率调度背后的直觉是，让优化持续进行，直到权重向量的分布达到一个驻点。 此时，我们才将学习率降低，以获得更高质量的代理来达到一个良好的局部最小值。

## 余弦调度器

余弦调度器是一种启发式算法。 它所依据的观点是：我们可能不想在一开始就太大地降低学习率，而且可能希望最终能用非常小的学习率来“改进”解决方案。 这产生了一个类似于余弦的调度，函数形式如下所示，学习率的值在 $t \in [0, T]$ 之间。

$$
\eta_t = \eta_T + \frac{\eta_0 - \eta_T}{2} \left(1 + \cos(\pi t/T)\right)$$

这里 $\eta_0$ 是初始学习率， $\eta_T$ 是当 $T$ 时的目标学习率。 此外，对于 $t > T$ ，我们只需将值固定到 $\eta_T$ 而不再增加它。 

```py
class CosineScheduler:
    def __init__(self, max_update, base_lr=0.01, final_lr=0,
               warmup_steps=0, warmup_begin_lr=0):
        self.base_lr_orig = base_lr
        self.max_update = max_update
        self.final_lr = final_lr
        self.warmup_steps = warmup_steps
        self.warmup_begin_lr = warmup_begin_lr
        self.max_steps = self.max_update - self.warmup_steps

    def get_warmup_lr(self, epoch):
        increase = (self.base_lr_orig - self.warmup_begin_lr) \
                       * float(epoch) / float(self.warmup_steps)
        return self.warmup_begin_lr + increase

    def __call__(self, epoch):
        if epoch < self.warmup_steps:
            return self.get_warmup_lr(epoch)
        if epoch <= self.max_update:
            self.base_lr = self.final_lr + (
                self.base_lr_orig - self.final_lr) * (1 + math.cos(
                math.pi * (epoch - self.warmup_steps) / self.max_steps)) / 2
        return self.base_lr
```

## 预热

在某些情况下，初始化参数不足以得到良好的解。 这对某些高级网络设计来说尤其棘手，可能导致不稳定的优化结果。 对此，一方面，我们可以选择一个足够小的学习率， 从而防止一开始发散，然而这样进展太缓慢。 另一方面，较高的学习率最初就会导致发散。

解决这种困境的一个相当简单的解决方法是使用预热期，在此期间学习率将增加至初始最大值，然后冷却直到优化过程结束。 为了简单起见，通常使用线性递增。 这引出了如下所示的时间表。

```py
scheduler = CosineScheduler(20, warmup_steps=5, base_lr=0.3, final_lr=0.01)
d2l.plot(torch.arange(num_epochs), [scheduler(t) for t in range(num_epochs)])
```

预热可以应用于任何调度器，而不仅仅是余弦。关于预热有一个很关键的发现：预热阶段限制了非常深的网络中参数的发散程度。这在直觉上是有道理的：在网络中那些一开始花费最多时间取得进展的部分，随机初始化会产生巨大的发散。

# Lec2

## Introduction

        当我们试图去识别一张图像时，一个很容易想到的函数框架是：

```py
def classify_image(image):
    # some magic here?
    return class_label
```

        然而其中的 `magic` 的实现，却非常困难。可以说，没有一个直观的方法能够通过一个 rgb 矩阵来识别图片。

        于是人们就有了以下的尝试。通过 Hubel and Wiesel 的实验我们知道了“线条”在视觉识别中起到非常重要的作用。我们是否可以通过计算这些边界的组合，例如找到三条线相交组成的一个角，然后通过这些线条和角的特征分类来识别图片？事实证明这种方法效果并不好。首先它的鲁棒性很差。另外，如果想要换一个识别目标，例如从识别猫改为识别卡车，那么一切都要重新来过。这并不是一个普适的、可扩展的识别方法。我们希望能得到一种能够识别世界上所有物体的算法。

        基于以上想法，<b>“数据驱动方法”</b>的思想诞生了。我们选择通过大量的数据来训练一个模型，而不是手工地来确定什么样的线条是猫、什么样的线条是卡车。也就是如下的框架：

```py
def train(images, labels):
    # Machine learning!
    return model

def predict(model, test_images):
    # Use model to predict labels
    return test_labels
```

## Nearest Neighbor Classification                

        一种基于“数据驱动方法”思想的<b>分类器（classifier）</b>叫做<b>“Nearest Neighbor”</b>，即 train 部分用于记忆所有的数据和标签，然后在 predict 部分，在记忆中寻找与之最接近的一张图片，它的标签就是识别图片的标签。下图是利用 Nearest Neighbor 训练出来的结果的示例。

![](/assets/Xlz4b7A8foNiJIxusTgc9eHmn7f.png)

        可以看到这种 classifier 的效果还是会有不少的误差，因为很多看起来非常接近的图片其实并不是一个东西。

        虽然 Nearest Neighbor 算法的实际效果并不尽如人意，但是这个过程中如何判断两张图片为 nearest neighbor 还是一件非常有意思的事情。一个非常简单的方法是利用 L1 distance （又称 Manhattan distance） 来比较两个矩阵。

![](/assets/MqhYbqr4qo2k7Lx32FOcNSlEnHh.png)

        利用 L1 distance 来实现 Nearest Neighbor 的代码如下：

```py
import numpy as np

class NearestNeighbor:
    def __init__(self):
        Xtr = None
        ytr = None
    
    def train(self, X, y):
        """ X is N x D where each row is an example. Y is 1-dimension of size N """
        # the nearest neighbor classifier simply remembers all the training data
        self.Xtr = X
        self.ytr = y
        
    def predict(self, X):
        """ X is N x D where each row is an example we wish to predict label for"""
        num_test = X.shape[0]
        # lets make sure that the output type matches the input type
        Ypred = np.zeros(num_test, dtype = type(self.ytr))
        
        # loop over all test rows
        for i in range(num_test):
            # find the nearest training image to the i'th test image
            # using the L1 distance(sum of absolute value differences)
            distances = np.sum(np.abs(self.Xtr - X[i, :]), axis = 1)
            min_index = np.argmin(distances)
            Ypred[i] = self.ytr[min_index]
            
        return Ypred
```

        这个算法的 train 复杂度几乎是常数的，因为它只需要把所有的内容都记下来，然而在 predict 阶段，会需要 O(N) 的复杂度。这也是我们不希望看到的，因为显而易见的是，我们可以花费大量的时间用于 train ，得到一个精确度很高的模型，但当我们应用这个模型来 predict 的时候，我们希望它能快速得出结果。

         一种对 Nearest Neighbor 算法的精确度的改进策略是使用 <b>K-Nearest Neighbors</b> 的想法。也就是说，对于一张图我们不再是寻找数据集中距离它最近的那一张图，而是寻找最近的 K 张图，并取最多的那一个标签作为测试图的标签结果。如下图所示的示例可以看到，当 K 取 5 时，决策边界已经相当平滑漂亮（图中的点表示数据集中的图片，点的颜色表示其标签，不同的颜色区块表示位于此区间的测试图的标签取区块的颜色）

![](/assets/XqHfbvgwQoMNhIxAzsocnIRUnJh.png)

        另外除了 L1 distance，也可以考虑使用 <b>L2 distance（Euclidean distance）</b>来距离。由于 L1 distance 会随坐标轴的旋转而改变，而 L2 distance 不会，故应根据场景的不同选择不同的路径算法。

![](/assets/Hcpxbz365ooqAjxxpRKc7qCXngf.png)

        在这个例子中， k 的选择和路径算法的选择称为<b>超参数（hyperparameters）</b>。超参数与模型中其他的参数的区别在于，其他的参数是模型通过训练得出的，而超参数则是人为设定的，用于控制学习的过程。超参数的设定非常取决于你希望解决的问题（problem-dependent），对绝大多数情况而言，选择超参数的最好方法是一一尝试过来，并选择其中表现最好的那一个。

        事实上，对于超参数的尝试和选择也有相应的方法。当拿到一个数据集，首先应当将其进行划分。如果不划分直接训练，那么任意的超参数都将表现非常好——因为你的所有数据全都拿来训练了。这将无法选出真正表现优秀的超参数。

        将数据集划分为训练数据和测试数据听起来是一个不错的主意，但也不可取。这种情况下，调整超参数将是这样的流程：设置一个超参数，然后在训练数据上跑训练，再用测试数据来看这个训练模型的表现，据此修改超参数并寻找最佳表现的超参数。这种方法的问题在于找出的超参数是最拟合测试数据的超参数，但我们对它面对其他未知数据的表现将不得而知。也就是说这种方法训练出来的模型将过于拟合测试数据而丧失普适性。

        一种常用的数据划分方法是将其划为三部分——大部分划分为训练数据，剩下的划分为调整数据和测试数据。训练数据用于跑训练，根据模型在调整数据上的表现来调整超参数，得到表现最好的超参数以后，用测试数据来看最终模型的结果，并将准确率写在报告、论文上。

![](/assets/ClpSbY7NqoONyMxPLZacVkCqnNe.png)

        当数据集不大时，还可以用准确率更高的方法，如 K-Cross Validation ，这种方法对数据集的划分是，除去少量的测试数据以外，其余的进行 k 等分，每次选取其中一部分作为调整数据，剩下的作为训练数据。循环 k 次后再在测试数据上进行最后测试。这种划分方法准确率更高，但效率要低很多，因此当数据量大的时候通常不采用。

![](/assets/CeW6bkinuoR3XlxoC5rc39jsnGe.png)

         事实上即使是改进后的 K-Nearest Neighbors 算法也依旧表现很不好。首先，它的运行效率较低。其次，L1 distance 和 L2 distance 用于图片比较距离并不是一个很好的想法。最后，由于这种算法其实可以看作是在点的周围根据距离不同涂上颜色，因此如果我们想要得到准确的结果就需要训练数据集中的点尽可能的密集。然而显而易见，这是随着维数的增长呈指数级增长的。这很不好。

![](/assets/U8j7b3jOwoCzWtxygSKcjw1fnVh.png)

## Linear Classification

        另一种思路是利用线性计算来给出一张图片属于 n 种分类的得分，得分最高的就是这张图片的分类。也就是说，利用 $f(x, W) = Wx$ ，其中 $x$ 是需要判断的图片，$W$ 是训练得到的矩阵，而得到的结果就是得分矩阵。$W$ 矩阵的大小是这样得到的：我们假设图片是 $32 \times 32 \times 3$ 的（即CIFAR-10提供图片的标准大小），那么 $x$ 矩阵可以用 $3072 \times 1$ 的矩阵来表示；假设总共有10个标签，那么我们最终希望得到的得分矩阵就是 $10 \times 1$。由矩阵乘法的规则可知，W 应为一个 $10 \times 3072$ 大小的矩阵。

![](/assets/MJqGbC8uooAYq4xa5AucJH6fnag.png)

        很多时候我们还会选择在 $Wx$ 之后加上一个常量 $b$ ，用于调整最后的结果。

        下图是一个具体的例子。

![](/assets/ELvgblHyXodANvxh6cRchwIPnZb.png)

        线性分类的公式到底在做什么？下图是一个根据 CIFAR-10 的数据训练出来的一个 $W$ 矩阵结果，通过这个结果我们可以大致看到这个训练过程结果究竟是什么。$W$ 中的每一行实际上可以看作是对相应种类的一个图片模版。当我们计算一张图片对于一个标签种类的得分的时候我们实际是在算这张图和这类图片的模版的点积，用于进行比较（类比 Nearest Neighbor 的思想，这里的点积类似于 L1 distance 或者 L2 distance ，区别在于我们不需要用成千上万的数据集来比较，而是通过一个训练完的模版进行比较）。

![](/assets/KxZcbYq4vosUfOxaZ04cKonPnod.png)

        从另一个角度来看，对于 W 中的每一行，实际上是对一个种类的分类器，它将平面划分为两部分；而 b 的存在则是为了防止所有的直线都经过原点。由这张图也可一看到，当区域并非线性的时候，用线性分类的方法就会遇到一些困难。

![](/assets/BQMfbWIQZovWbBxRrnvc6yJInib.png)

# Lec3

## Loss Function

        在 Linear Classifier 的训练过程中，我们可能会得到一系列的 $W$ 值，而这些 $W$ 的值会有不同的表现。这个时候我们希望能有一个函数来表示我们对这个 $W$ 值的表现的满意程度。这个函数就是 Loss Function。

        假设现在有数据集  $\{(x_i, y_i)\}_{i=1}^{N}$ ，其中  $x_i$ 是图片， $y_i$ 是（整数）标签，那么对这个数据集和当前 $W$ 的 loss function 是：

$$L=\frac1N \Sigma_{i=1}^N L_i(f(x_i,W),y_i)$$

### Multiclass SVM loss

        一种 loss function 叫做 Multiclass SVM loss ，有如下的 $L_i$ 计算方式（$s = f(x_i,W)$，$s_i$ 表示 $s$ 的第 $i$ 行）：

$$
L_i =\Sigma_{j\neq y_i} max(0, s_j - s_{y_i}+1)$$

        即

$$
L_i = \Sigma_{j\neq y_i}\left\{ \begin{aligned} 0 &&if\ s_{y_i} \geq s_j + 1\\ s_j - s_{y_i} + 1 && otherwise\\ \end{aligned} \right.$$

        这里的 $1$ 是设定的安全边际。公式对应的图像为：

![](/assets/Utp1bA50Co7te3xZQZjcX8fKnZg.png)

        这种 loss function 被称为 Hinge Loss ，在安全边际之前 loss function 线性降低，而之后其值为 $0$ 。

        计算这类 loss function 的 python 代码如下：

```py
def L_i_vectorized(x, y, W):
    scores = W.dot(x)
    margins = np.maximum(0, scores - scores[y] + 1)
    margins[y] = 0
    loss_i = np.sum(margins)
    return loss_i
```

        事实上仅仅通过这样的 loss function 很容易导致的一个问题就是训练得到的模型过于拟合训练数据，但实际上我们并不关心训练数据。我们希望它面对测试数据的时候也能有很好的表现。但是过于拟合训练数据的模型往往在面对新数据的时候表现并不好。如下图，蓝色点表示训练数据，蓝线表示拟合的模型（这不是线性的，是一个更一般的例子），绿色方块表示测试数据。可以看到尽管这条蓝线对蓝色点的拟合非常好，但是当面对绿色方块的时候，它的表现就不是那么优秀了。实际上我们更希望得到的是绿色的这条线。

![](/assets/Oq9EbQ5Iio9Ca2xlvrDcnaTCnae.png)

        对于这个问题，通常我们选择在 loss function 后再加一项 regularization ，这一项鼓励模型在训练的过程中选择更简单的那一种，以期在测试数据上得到更好的表现（由奥卡姆剃刀原理的思想），如下：

$$L(W) = \frac1N \Sigma_{i=1}^N L_i + \lambda R(W)$$

        这里的 $\lambda$ 也是一个超参数，用于调整 $L_i$ 和 $R(W)$ 之间的比例。

        一些常用的 $R(W)$ 如下：

### Softmax Loss

        另一种计算方式是 Softmax ，这种计算方式如下：

$$P(Y=k | X = x_i) = \frac{e^{s_k}}{\Sigma_j e^{s_j}} \ \ \ \ \ s = f(x_i,W)$$

$$L_i = -logP(Y=y_i|X=x_i)$$

        即：

$$L_i = -log(\frac{e^s{y_i}}{\Sigma_j e^{s_j}})$$

### Softmax vs. SVM

        两种 loss function 的计算过程示意图如下：

![](/assets/Ci7ebbUgwopi3hxDpQCcozVOnjd.png)

        两者之间一个很大的区别在于，对于 SVM ，它关心的是正确分类的得分是否比其他得分高，只要正确得分确实比其他得分 + 安全边际要高，那么得到的 $L_i$ 就是 $0$ ，也就是说它的目标就是正确分类得分大于错误得分 + 安全边际。而对于 Softmax 而言，它总是希望正确分类的概率能够达到 $1$ ，也就是正确的得分趋向正无穷，而其他得分趋向负无穷（当然计算机对无穷的支持并不是那么优秀）。因此，不管现在训练的模型如何， Softmax 总是希望这个模型能够训练得更好。P. S. 从实际应用上来看两者并没有那么大的区别。

## Optimization

        那么，有了 loss function 以后，我们已经知道如何评估一个 $W$ 矩阵的表现。那么，我们如何才能找到表现最优的那个 $W$ 矩阵呢？

        首先最容易想到的办法就是随机搜索，每次随机一个 $W$ 矩阵，然后看这个矩阵表现如何，如果比当前最优的模型优那么就更新。显然，这种方法非常愚蠢，效率低下且训练结果也很难保证。

        另一种想法是对于当前的 $W$ 矩阵，我们试图去寻找其附近的局部最优解，并希望不断重复这个过程能够引领我们找到全局最优解。当然这很可能是找不到的，但即便如此，不断地找寻局部最优解这样的方法在实践中依然表现出了非常优秀的结果。

        对 $1$ 维的直线而言，寻找局部最优非常简单，只需要在当前位置的极限即可计算，如下：

$$\frac{df(x)}{dx} = \lim\limits_{h \rightarrow 0} \frac{f(x + h) - f(x)}{h}$$

        而对多维而言，则需要用到梯度的概念。梯度是一个向量，其每一个维度的值是函数在这个维度的斜率。由数学推导可知，函数在一点沿梯度方向变化最大，也就是说可以利用梯度来求得局部最优的 $W$ 矩阵。

        在计算梯度的时候，也有两种不同的做法。一种是通过每次给 $W$ 的一个维度加上一个很小的量，然后计算出两次 $f(W)$ 的值的差别，再除上这个很小的量，得到梯度在这个维度的值。这个方法的效率很低且精度有限，并不好。更好的方法是利用微积分的知识来求得梯度。当然数值计算的方法并非完全没有用，恰恰相反，利用数值计算来检验微分计算的正确性是很常见的手法，因为微分分析很容易出错。

        有了梯度以后，我们便可以得到一个非常简短却是很多深度学习的核心思路的代码：

```py
while True:
    weights_grad = evaluate_gradient(loss_fun, data, weights)
    weights += -step_size * weights_grad
```

        实际操作中还有一个小技巧。由于 loss function 的计算需要把所有数据的 loss 取平均，因此当数据量很大的时候每一次计算梯度都需要耗费非常多的时间。因此在计算梯度的时候，我们会考虑从所有的数据集中随机地取出一部分来代替所有数据，如下：

```py
while True:
    data_batch = sample_training_data(data, 256)
    weights_grad = evaluate_gradient(loss_fun, data_batch, weights)
    weights += -step_size * weights_grad
```

## Image Features

        事实上，由于多模态等原因，直接将图片像素信息不加任何处理地送进线性分类器，得到的结果往往不慎理想。因此在深度神经网络之前，人们往往采用两步来进行模型的训练。首先是将图片中的一些特征信息提取出来，计算得到数值，然后再把这些数值送进线性分类器。当然这个提取信息的过程需要根据图片信息而定。一个很简单的例子是在二维平面上的一些点。如果用经典的笛卡尔坐标系，则很难用线性分类进行区分；但如果进行特征提取转换为极坐标，那么就比较容易可以用线性分类器分开。

![](/assets/GzkKbAn8nobQYuxHV9WcxTm0nNe.png)

        应用到实际中，一种常见的特征值提取叫做 Color Histogram （颜色直方图）。这种方法是将颜色大致分为几种，然后把每一个像素点的颜色按照分类计数。例如下图中的青蛙，得到的特征值中的绿色数量就占大多数。

![](/assets/Wecib2mhzo3gqcxwD4ccu32Znye.png)

        还有一种很常见的特征值是 Histogram of Oriented Gradients 。上一讲有讲到边缘对视觉识别非常重要，因此提取边缘特征放进训练也是一种很好用的方法。例如把一张图分为 $8 \times 8$ 的小区域，每一个区域中有 $9$ 个方向信息，这样一张 $320 \times 240$ 的图片就可以用 $10800$ 个数来表示其边缘特征值。

![](/assets/BJjcbVCocouc5TxXNFdcQmINnwb.png)

